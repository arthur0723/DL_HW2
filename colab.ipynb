{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE20XaKGxR1I",
        "outputId": "5f11a2da-e790-4b24-9a76-7b4368e36119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "ğŸ“ æ­£åœ¨é€£æ¥Google Drive...\n",
            "Mounted at /content/drive\n",
            "âœ… Google Driveé€£æ¥æˆåŠŸï¼\n",
            "âœ… æ‰¾åˆ°è³‡æ–™å¤¾: /content/drive/MyDrive/data\n",
            "imagenette_160\tmini_coco_det  mini_voc_seg\n",
            "âœ… é©—è­‰è³‡æ–™å®Œæ•´æ€§...\n",
            "âœ… mini_coco_det å­˜åœ¨\n",
            "train\n",
            "val\n",
            "âœ… mini_voc_seg å­˜åœ¨\n",
            "class_mapping.txt\n",
            "dataset_config.txt\n",
            "train\n",
            "âœ… imagenette_160 å­˜åœ¨\n",
            "train\n",
            "val\n",
            "\n",
            "ğŸ¯ è³‡æ–™è·¯å¾‘è¨­å®šç‚º: /content/drive/MyDrive/data\n",
            "ğŸ”§ ä½¿ç”¨è¨­å‚™: cuda\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ç¬¬ä¸€æ®µï¼šé€£æ¥Google Driveä¸¦ç›´æ¥ä½¿ç”¨è³‡æ–™\n",
        "# =============================================================================\n",
        "\n",
        "# å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install efficientnet-pytorch -q\n",
        "!pip install timm -q\n",
        "\n",
        "# é€£æ¥Google Drive\n",
        "print(\"ğŸ“ æ­£åœ¨é€£æ¥Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# æª¢æŸ¥Driveé€£æ¥ç‹€æ…‹\n",
        "import os\n",
        "print(\"âœ… Google Driveé€£æ¥æˆåŠŸï¼\")\n",
        "\n",
        "# è¨­ç½®è³‡æ–™è·¯å¾‘ (è«‹æ ¹æ“šä½ çš„è³‡æ–™å¤¾ä½ç½®èª¿æ•´)\n",
        "data_root = \"/content/drive/MyDrive/data\"  # ä½ å¯èƒ½éœ€è¦èª¿æ•´é€™å€‹è·¯å¾‘\n",
        "\n",
        "# æª¢æŸ¥è³‡æ–™æ˜¯å¦å­˜åœ¨\n",
        "if os.path.exists(data_root):\n",
        "    print(f\"âœ… æ‰¾åˆ°è³‡æ–™å¤¾: {data_root}\")\n",
        "    !ls \"{data_root}\"\n",
        "else:\n",
        "    print(f\"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {data_root}\")\n",
        "    print(\"è«‹ç¢ºèªä½ çš„è³‡æ–™å¤¾è·¯å¾‘ï¼Œå¯èƒ½çš„ä½ç½®:\")\n",
        "    !find \"/content/drive/MyDrive/\" -name \"mini_coco_det\" -o -name \"mini_voc_seg\" -o -name \"imagenette_160\" 2>/dev/null\n",
        "\n",
        "# é©—è­‰è³‡æ–™çµæ§‹\n",
        "print(\"âœ… é©—è­‰è³‡æ–™å®Œæ•´æ€§...\")\n",
        "data_folders = ['mini_coco_det', 'mini_voc_seg', 'imagenette_160']\n",
        "for folder in data_folders:\n",
        "    folder_path = f'{data_root}/{folder}'\n",
        "    if os.path.exists(folder_path):\n",
        "        print(f\"âœ… {folder} å­˜åœ¨\")\n",
        "        # å¿«é€Ÿæª¢æŸ¥å…§å®¹\n",
        "        !ls \"{folder_path}\" | head -3\n",
        "    else:\n",
        "        print(f\"âŒ {folder} ä¸å­˜åœ¨\")\n",
        "\n",
        "print(f\"\\nğŸ¯ è³‡æ–™è·¯å¾‘è¨­å®šç‚º: {data_root}\")\n",
        "\n",
        "# æª¢æŸ¥GPU\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬äºŒæ®µï¼šè³‡æ–™è¼‰å…¥é¡åˆ¥å®šç¾©\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# åˆ†å‰²è³‡æ–™è¼‰å…¥å™¨\n",
        "class SegmentationDataLoader(Dataset):\n",
        "    \"\"\"åˆ†å‰²è³‡æ–™è¼‰å…¥å™¨ - å‰µæ–°ï¼šæ™ºèƒ½é¡åˆ¥æ¬Šé‡\"\"\"\n",
        "    def __init__(self, root_dir, split='train', transforms=None, img_size=512):\n",
        "        self.root = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.size = img_size\n",
        "        self.num_classes = 8\n",
        "\n",
        "        # è¼‰å…¥åœ–ç‰‡å’Œé®ç½©è·¯å¾‘\n",
        "        self.img_dir = os.path.join(root_dir, split, 'images')\n",
        "        self.mask_dir = os.path.join(root_dir, split, 'masks')\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "\n",
        "        for img_file in os.listdir(self.img_dir):\n",
        "            if img_file.endswith('.jpg'):\n",
        "                img_path = os.path.join(self.img_dir, img_file)\n",
        "                mask_path = os.path.join(self.mask_dir, img_file.replace('.jpg', '.png'))\n",
        "                if os.path.exists(mask_path):\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.mask_paths.append(mask_path)\n",
        "\n",
        "        print(f\"Segmentation {split}: {len(self.image_paths)} samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # è¼‰å…¥åœ–ç‰‡\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "\n",
        "        # è¼‰å…¥é®ç½©\n",
        "        mask = Image.open(self.mask_paths[idx])\n",
        "        mask = np.array(mask)\n",
        "        mask = np.where(mask >= self.num_classes, 255, mask)\n",
        "        mask = torch.tensor(mask, dtype=torch.long)\n",
        "\n",
        "        # æ‡‰ç”¨è½‰æ›\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            # èª¿æ•´é®ç½©å¤§å°\n",
        "            mask = F.interpolate(\n",
        "                mask.unsqueeze(0).unsqueeze(0).float(),\n",
        "                size=(self.size, self.size),\n",
        "                mode='nearest'\n",
        "            ).squeeze().long()\n",
        "\n",
        "        return {\n",
        "            'input': image,\n",
        "            'target': mask\n",
        "        }\n",
        "\n",
        "# æª¢æ¸¬è³‡æ–™è¼‰å…¥å™¨\n",
        "class DetectionDataLoader(Dataset):\n",
        "    \"\"\"æª¢æ¸¬è³‡æ–™è¼‰å…¥å™¨ - å‰µæ–°ï¼šæ™ºèƒ½ç›®æ¨™ç·¨ç¢¼\"\"\"\n",
        "    def __init__(self, root_dir, split='train', transforms=None, img_size=512):\n",
        "        self.root = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.size = img_size\n",
        "\n",
        "        # è¼‰å…¥COCOæ ¼å¼æ¨™è¨»\n",
        "        ann_file = os.path.join(root_dir, split, 'annotations', f'instances_{split}2017.json')\n",
        "        with open(ann_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "\n",
        "        # å»ºç«‹é¡åˆ¥æ˜ å°„\n",
        "        all_category_ids = sorted(set(ann['category_id'] for ann in self.coco_data['annotations']))\n",
        "        self.category_mapping = {old_id: new_id for new_id, old_id in enumerate(all_category_ids)}\n",
        "        self.num_classes = len(all_category_ids)\n",
        "\n",
        "        # å»ºç«‹åœ–ç‰‡åˆ°æ¨™è¨»çš„æ˜ å°„\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.img_to_anns:\n",
        "                self.img_to_anns[img_id] = []\n",
        "            self.img_to_anns[img_id].append(ann)\n",
        "\n",
        "        # éæ¿¾æœ‰æ¨™è¨»çš„åœ–ç‰‡\n",
        "        self.images = [img for img in self.coco_data['images'] if img['id'] in self.img_to_anns]\n",
        "\n",
        "        print(f\"Detection {split}: {len(self.images)} samples, {self.num_classes} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_info = self.images[idx]\n",
        "        img_id = img_info['id']\n",
        "\n",
        "        # è¼‰å…¥åœ–ç‰‡\n",
        "        img_path = os.path.join(self.root, self.split, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        orig_w, orig_h = image.size\n",
        "\n",
        "        # è¼‰å…¥æ¨™è¨»\n",
        "        annotations = self.img_to_anns[img_id]\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in annotations:\n",
        "            bbox = ann['bbox']  # [x, y, width, height]\n",
        "            x1, y1, w, h = bbox\n",
        "            x2, y2 = x1 + w, y1 + h\n",
        "\n",
        "            # æ­£è¦åŒ–åˆ°[0,1]ä¸¦è½‰æ›ç‚ºä¸­å¿ƒæ ¼å¼\n",
        "            cx = (x1 + x2) / 2 / orig_w\n",
        "            cy = (y1 + y2) / 2 / orig_h\n",
        "            w_norm = w / orig_w\n",
        "            h_norm = h / orig_h\n",
        "\n",
        "            boxes.append([cx, cy, w_norm, h_norm])\n",
        "\n",
        "            # æ˜ å°„æ¨™ç±¤\n",
        "            original_label = ann['category_id']\n",
        "            mapped_label = self.category_mapping[original_label]\n",
        "            labels.append(mapped_label)\n",
        "\n",
        "        # æ‡‰ç”¨è½‰æ›\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4))\n",
        "        labels = torch.tensor(labels, dtype=torch.long) if labels else torch.zeros((0,), dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'input': image,\n",
        "            'boxes': boxes,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "# åˆ†é¡è³‡æ–™è¼‰å…¥å™¨\n",
        "class ClassificationDataLoader(Dataset):\n",
        "    \"\"\"åˆ†é¡è³‡æ–™è¼‰å…¥å™¨\"\"\"\n",
        "    def __init__(self, root_dir, split='train', transforms=None):\n",
        "        self.root = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # ImageNetteé¡åˆ¥\n",
        "        self.class_names = [\n",
        "            'n01440764', 'n02102040', 'n02979186', 'n03000684', 'n03028079',\n",
        "            'n03394916', 'n03417042', 'n03425413', 'n03445777', 'n03888257'\n",
        "        ]\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.class_names)}\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        # è¼‰å…¥è³‡æ–™\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        split_dir = os.path.join(root_dir, split)\n",
        "        for class_name in self.class_names:\n",
        "            class_dir = os.path.join(split_dir, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                for img_file in os.listdir(class_dir):\n",
        "                    if img_file.endswith('.JPEG'):\n",
        "                        self.image_paths.append(os.path.join(class_dir, img_file))\n",
        "                        self.labels.append(self.class_to_idx[class_name])\n",
        "\n",
        "        print(f\"Classification {split}: {len(self.image_paths)} samples, {self.num_classes} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return {\n",
        "            'input': image,\n",
        "            'target': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\"âœ… è³‡æ–™è¼‰å…¥é¡åˆ¥å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WN23d5MBMO8",
        "outputId": "fff83994-0c69-4ab7-b767-19f54dd90246"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è³‡æ–™è¼‰å…¥é¡åˆ¥å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬ä¸‰æ®µï¼šè³‡æ–™è½‰æ›å’Œè³‡æ–™ç®¡ç†å™¨\n",
        "# =============================================================================\n",
        "\n",
        "# ä»»å‹™æ„ŸçŸ¥è½‰æ›å™¨\n",
        "class TaskAwareTransforms:\n",
        "    \"\"\"ä»»å‹™æ„ŸçŸ¥è½‰æ›å™¨ - å‰µæ–°ï¼šé‡å°ä¸åŒä»»å‹™å„ªåŒ–è½‰æ›\"\"\"\n",
        "    def __init__(self, img_size=512):\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # åŸºç¤æ­£è¦åŒ–\n",
        "        self.normalize = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "\n",
        "    def get_seg_transforms(self, is_training=True):\n",
        "        \"\"\"åˆ†å‰²ä»»å‹™å°ˆç”¨è½‰æ›\"\"\"\n",
        "        if is_training:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "        else:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "\n",
        "    def get_det_transforms(self, is_training=True):\n",
        "        \"\"\"æª¢æ¸¬ä»»å‹™å°ˆç”¨è½‰æ›\"\"\"\n",
        "        if is_training:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.RandomHorizontalFlip(p=0.3),  # æª¢æ¸¬ç”¨è¼ƒå°çš„ç¿»è½‰æ©Ÿç‡\n",
        "                transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "        else:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "\n",
        "    def get_cls_transforms(self, is_training=True):\n",
        "        \"\"\"åˆ†é¡ä»»å‹™å°ˆç”¨è½‰æ›\"\"\"\n",
        "        if is_training:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(10),\n",
        "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "        else:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize((self.img_size, self.img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                self.normalize\n",
        "            ])\n",
        "\n",
        "# æ‰¹æ¬¡æ•´ç†å‡½æ•¸\n",
        "def smart_collate_fn(batch):\n",
        "    \"\"\"æ™ºèƒ½æ‰¹æ¬¡æ•´ç†å‡½æ•¸\"\"\"\n",
        "    # æª¢æ¸¬ä»»å‹™\n",
        "    if 'boxes' in batch[0]:\n",
        "        return detection_collate(batch)\n",
        "    # åˆ†å‰²ä»»å‹™ï¼ˆtargetæ˜¯tensorä¸”ç¶­åº¦>0ï¼‰\n",
        "    elif 'target' in batch[0] and hasattr(batch[0]['target'], 'dim') and batch[0]['target'].dim() > 0:\n",
        "        return segmentation_collate(batch)\n",
        "    # åˆ†é¡ä»»å‹™\n",
        "    else:\n",
        "        return classification_collate(batch)\n",
        "\n",
        "def detection_collate(batch):\n",
        "    \"\"\"æª¢æ¸¬æ‰¹æ¬¡æ•´ç†\"\"\"\n",
        "    inputs = torch.stack([item['input'] for item in batch])\n",
        "    boxes = [item['boxes'] for item in batch]\n",
        "    labels = [item['labels'] for item in batch]\n",
        "\n",
        "    return {\n",
        "        'inputs': inputs,\n",
        "        'boxes': boxes,\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "def segmentation_collate(batch):\n",
        "    \"\"\"åˆ†å‰²æ‰¹æ¬¡æ•´ç†\"\"\"\n",
        "    inputs = torch.stack([item['input'] for item in batch])\n",
        "    targets = torch.stack([item['target'] for item in batch])\n",
        "\n",
        "    return {\n",
        "        'inputs': inputs,\n",
        "        'targets': targets\n",
        "    }\n",
        "\n",
        "def classification_collate(batch):\n",
        "    \"\"\"åˆ†é¡æ‰¹æ¬¡æ•´ç†\"\"\"\n",
        "    inputs = torch.stack([item['input'] for item in batch])\n",
        "    targets = torch.stack([item['target'] for item in batch])\n",
        "\n",
        "    return {\n",
        "        'inputs': inputs,\n",
        "        'targets': targets\n",
        "    }\n",
        "\n",
        "# è³‡æ–™ç®¡ç†å™¨\n",
        "class DataManager:\n",
        "    \"\"\"è³‡æ–™ç®¡ç†å™¨ - å‰µæ–°ï¼šçµ±ä¸€ç®¡ç†æ‰€æœ‰ä»»å‹™è³‡æ–™\"\"\"\n",
        "    def __init__(self, data_root, batch_size=8, img_size=512, num_workers=2):\n",
        "        self.data_root = data_root\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        # å‰µå»ºä»»å‹™æ„ŸçŸ¥è½‰æ›å™¨\n",
        "        self.task_transforms = TaskAwareTransforms(img_size)\n",
        "\n",
        "    def create_all_loaders(self):\n",
        "        \"\"\"å‰µå»ºæ‰€æœ‰ä»»å‹™çš„è³‡æ–™è¼‰å…¥å™¨\"\"\"\n",
        "        print(\"ğŸ“Š å‰µå»ºè³‡æ–™è¼‰å…¥å™¨...\")\n",
        "\n",
        "        # åˆ†å‰²è³‡æ–™\n",
        "        seg_train_dataset = SegmentationDataLoader(\n",
        "            os.path.join(self.data_root, 'mini_voc_seg'),\n",
        "            'train',\n",
        "            self.task_transforms.get_seg_transforms(True),\n",
        "            self.img_size\n",
        "        )\n",
        "        seg_val_dataset = SegmentationDataLoader(\n",
        "            os.path.join(self.data_root, 'mini_voc_seg'),\n",
        "            'val',\n",
        "            self.task_transforms.get_seg_transforms(False),\n",
        "            self.img_size\n",
        "        )\n",
        "\n",
        "        # æª¢æ¸¬è³‡æ–™\n",
        "        det_train_dataset = DetectionDataLoader(\n",
        "            os.path.join(self.data_root, 'mini_coco_det'),\n",
        "            'train',\n",
        "            self.task_transforms.get_det_transforms(True),\n",
        "            self.img_size\n",
        "        )\n",
        "        det_val_dataset = DetectionDataLoader(\n",
        "            os.path.join(self.data_root, 'mini_coco_det'),\n",
        "            'val',\n",
        "            self.task_transforms.get_det_transforms(False),\n",
        "            self.img_size\n",
        "        )\n",
        "\n",
        "        # åˆ†é¡è³‡æ–™\n",
        "        cls_train_dataset = ClassificationDataLoader(\n",
        "            os.path.join(self.data_root, 'imagenette_160'),\n",
        "            'train',\n",
        "            self.task_transforms.get_cls_transforms(True)\n",
        "        )\n",
        "        cls_val_dataset = ClassificationDataLoader(\n",
        "            os.path.join(self.data_root, 'imagenette_160'),\n",
        "            'val',\n",
        "            self.task_transforms.get_cls_transforms(False)\n",
        "        )\n",
        "\n",
        "        # å‰µå»ºDataLoader\n",
        "        seg_train_loader = DataLoader(\n",
        "            seg_train_dataset, batch_size=self.batch_size//2, shuffle=True,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "        seg_val_loader = DataLoader(\n",
        "            seg_val_dataset, batch_size=self.batch_size//2, shuffle=False,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "\n",
        "        det_train_loader = DataLoader(\n",
        "            det_train_dataset, batch_size=self.batch_size//2, shuffle=True,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "        det_val_loader = DataLoader(\n",
        "            det_val_dataset, batch_size=self.batch_size//2, shuffle=False,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "\n",
        "        cls_train_loader = DataLoader(\n",
        "            cls_train_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "        cls_val_loader = DataLoader(\n",
        "            cls_val_dataset, batch_size=self.batch_size, shuffle=False,\n",
        "            num_workers=self.num_workers, collate_fn=smart_collate_fn\n",
        "        )\n",
        "\n",
        "        # ç²å–é¡åˆ¥è³‡è¨Š\n",
        "        category_info = {\n",
        "            'segmentation_classes': seg_train_dataset.num_classes,\n",
        "            'detection_classes': det_train_dataset.num_classes,\n",
        "            'classification_classes': cls_train_dataset.num_classes,\n",
        "            'detection_mapping': det_train_dataset.category_mapping\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'segmentation': (seg_train_loader, seg_val_loader),\n",
        "            'detection': (det_train_loader, det_val_loader),\n",
        "            'classification': (cls_train_loader, cls_val_loader),\n",
        "            'category_info': category_info\n",
        "        }\n",
        "\n",
        "# æ¸¬è©¦è³‡æ–™ç®¡ç†å™¨\n",
        "print(\"ğŸ§ª æ¸¬è©¦è³‡æ–™ç®¡ç†å™¨...\")\n",
        "data_manager = DataManager(data_root, batch_size=4)\n",
        "all_loaders = data_manager.create_all_loaders()\n",
        "\n",
        "print(\"âœ… è³‡æ–™ç®¡ç†å™¨å‰µå»ºå®Œæˆ\")\n",
        "print(f\"ğŸ“Š é¡åˆ¥è³‡è¨Š: {all_loaders['category_info']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOPlwCwHDFic",
        "outputId": "6d7d8a91-ddc3-487b-a0e6-c6fed0559b8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª æ¸¬è©¦è³‡æ–™ç®¡ç†å™¨...\n",
            "ğŸ“Š å‰µå»ºè³‡æ–™è¼‰å…¥å™¨...\n",
            "Segmentation train: 240 samples\n",
            "Segmentation val: 60 samples\n",
            "Detection train: 240 samples, 10 classes\n",
            "Detection val: 60 samples, 10 classes\n",
            "Classification train: 240 samples, 10 classes\n",
            "Classification val: 60 samples, 10 classes\n",
            "âœ… è³‡æ–™ç®¡ç†å™¨å‰µå»ºå®Œæˆ\n",
            "ğŸ“Š é¡åˆ¥è³‡è¨Š: {'segmentation_classes': 8, 'detection_classes': 10, 'classification_classes': 10, 'detection_mapping': {1: 0, 3: 1, 8: 2, 15: 3, 31: 4, 44: 5, 47: 6, 51: 7, 62: 8, 67: 9}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬å››æ®µï¼šæ¨¡å‹æ¶æ§‹å®šç¾©\n",
        "# =============================================================================\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# EfficientNetç‰¹å¾µæå–å™¨\n",
        "class EfficientNetExtractor(nn.Module):\n",
        "    \"\"\"EfficientNetç‰¹å¾µæå–å™¨\"\"\"\n",
        "    def __init__(self, model_name='efficientnet-b0', pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # è¼‰å…¥é è¨“ç·´EfficientNet\n",
        "        if pretrained:\n",
        "            self.backbone = EfficientNet.from_pretrained(model_name)\n",
        "        else:\n",
        "            self.backbone = EfficientNet.from_name(model_name)\n",
        "\n",
        "        # ç§»é™¤åˆ†é¡é ­\n",
        "        self.backbone._fc = nn.Identity()\n",
        "\n",
        "        # å‡çµå‰é¢çš„å±¤ä»¥æ§åˆ¶åƒæ•¸é‡\n",
        "        self._freeze_early_layers()\n",
        "\n",
        "        # ç²å–å¯¦éš›çš„ç‰¹å¾µé€šé“æ•¸\n",
        "        self.feature_channels = self._get_feature_channels()\n",
        "\n",
        "        print(f\"âœ… EfficientNet-B0 è¼‰å…¥å®Œæˆ\")\n",
        "        print(f\"ğŸ“Š ç‰¹å¾µé€šé“æ•¸: {self.feature_channels}\")\n",
        "        self._print_param_count()\n",
        "\n",
        "    def _freeze_early_layers(self):\n",
        "        \"\"\"å‡çµå‰é¢çš„å±¤ä»¥æ¸›å°‘åƒæ•¸é‡\"\"\"\n",
        "        # å‡çµå‰8å€‹block\n",
        "        for i, block in enumerate(self.backbone._blocks):\n",
        "            if i < 8:\n",
        "                for param in block.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "    def _get_feature_channels(self):\n",
        "        \"\"\"å‹•æ…‹ç²å–ç‰¹å¾µé€šé“æ•¸\"\"\"\n",
        "        # æ¸¬è©¦å‰å‘å‚³æ’­ä¾†ç²å–å¯¦éš›é€šé“æ•¸\n",
        "        test_input = torch.randn(1, 3, 224, 224)\n",
        "        features = self._extract_features(test_input)\n",
        "\n",
        "        channels = {\n",
        "            'p3': features['p3'].shape[1],\n",
        "            'p4': features['p4'].shape[1],\n",
        "            'p5': features['p5'].shape[1]\n",
        "        }\n",
        "        return channels\n",
        "\n",
        "    def _extract_features(self, x):\n",
        "        \"\"\"æå–ç‰¹å¾µçš„å…§éƒ¨æ–¹æ³•\"\"\"\n",
        "        features = []\n",
        "\n",
        "        # Stem\n",
        "        x = self.backbone._swish(self.backbone._bn0(self.backbone._conv_stem(x)))\n",
        "\n",
        "        # Blocks\n",
        "        for idx, block in enumerate(self.backbone._blocks):\n",
        "            drop_connect_rate = self.backbone._global_params.drop_connect_rate\n",
        "            if drop_connect_rate:\n",
        "                drop_connect_rate *= float(idx) / len(self.backbone._blocks)\n",
        "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
        "\n",
        "            # æå–ç‰¹å®šå±¤çš„ç‰¹å¾µ\n",
        "            if idx in [2, 5, 10]:  # å°æ‡‰ä¸åŒå°ºåº¦\n",
        "                features.append(x)\n",
        "\n",
        "        # Head conv\n",
        "        x = self.backbone._swish(self.backbone._bn1(self.backbone._conv_head(x)))\n",
        "        features.append(x)\n",
        "\n",
        "        # ç¢ºä¿è‡³å°‘æœ‰3å€‹ç‰¹å¾µ\n",
        "        while len(features) < 3:\n",
        "            features.append(features[-1])\n",
        "\n",
        "        return {\n",
        "            'p3': features[0],\n",
        "            'p4': features[1],\n",
        "            'p5': features[2]\n",
        "        }\n",
        "\n",
        "    def _print_param_count(self):\n",
        "        \"\"\"å°å‡ºåƒæ•¸çµ±è¨ˆ\"\"\"\n",
        "        total = sum(p.numel() for p in self.parameters())\n",
        "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        print(f\"ç¸½åƒæ•¸: {total/1e6:.2f}M, å¯è¨“ç·´: {trainable/1e6:.2f}M\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"æå–å¤šå°ºåº¦ç‰¹å¾µ\"\"\"\n",
        "        return self._extract_features(x)\n",
        "\n",
        "# å‹•æ…‹ç‰¹å¾µèåˆ (Neck)\n",
        "class DynamicFeatureFusion(nn.Module):\n",
        "    \"\"\"å‹•æ…‹ç‰¹å¾µèåˆ - ç¬¦åˆNecké™åˆ¶çš„å‰µæ–°\"\"\"\n",
        "    def __init__(self, backbone_channels, output_channels=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # æ ¹æ“šå¯¦éš›é€šé“æ•¸å‰µå»ºé©é…å™¨\n",
        "        self.p3_adapter = nn.Conv2d(backbone_channels['p3'], output_channels, 1)\n",
        "        self.p4_adapter = nn.Conv2d(backbone_channels['p4'], output_channels, 1)\n",
        "\n",
        "        # å‰µæ–°ï¼šå¯å­¸ç¿’çš„èåˆæ¬Šé‡\n",
        "        self.fusion_weights = nn.Parameter(torch.ones(2))\n",
        "\n",
        "        # å–®å±¤FPN (ç¬¦åˆä½œæ¥­é™åˆ¶)\n",
        "        self.fusion_conv = nn.Sequential(\n",
        "            nn.Conv2d(output_channels, output_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… ç‰¹å¾µèåˆå±¤å‰µå»º: P3({backbone_channels['p3']})â†’{output_channels}, P4({backbone_channels['p4']})â†’{output_channels}\")\n",
        "\n",
        "    def forward(self, features):\n",
        "        p3, p4 = features['p3'], features['p4']\n",
        "\n",
        "        # èª¿æ•´é€šé“æ•¸\n",
        "        p3_feat = self.p3_adapter(p3)\n",
        "        p4_feat = self.p4_adapter(p4)\n",
        "\n",
        "        # ä¸Šæ¡æ¨£P4åˆ°P3å°ºå¯¸\n",
        "        p4_up = F.interpolate(p4_feat, size=p3_feat.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # å‰µæ–°ï¼šå‹•æ…‹æ¬Šé‡èåˆ\n",
        "        weights = F.softmax(self.fusion_weights, dim=0)\n",
        "        fused = weights[0] * p3_feat + weights[1] * p4_up\n",
        "\n",
        "        # ä¸‹æ¡æ¨£åˆ°ç›®æ¨™å°ºå¯¸ (stride 16)\n",
        "        output = F.max_pool2d(fused, kernel_size=2, stride=2)\n",
        "        output = self.fusion_conv(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# ä»»å‹™æ„ŸçŸ¥å±¤ (å‰µæ–°æ ¸å¿ƒ)\n",
        "class TaskAwarenessLayer(nn.Module):\n",
        "    \"\"\"ä»»å‹™æ„ŸçŸ¥å±¤ - åœ¨é™åˆ¶å…§çš„æœ€å¤§å‰µæ–°\"\"\"\n",
        "    def __init__(self, channels=128, num_tasks=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # å‰µæ–°1: è¼•é‡ç´šä»»å‹™åµŒå…¥\n",
        "        self.task_embeddings = nn.Parameter(torch.randn(num_tasks, channels // 4))\n",
        "\n",
        "        # å‰µæ–°2: é€šé“æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // 8, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // 8, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # å‰µæ–°3: ä»»å‹™èª¿åˆ¶å·ç©\n",
        "        self.modulation_conv = nn.Conv2d(channels, channels, 3, 1, 1)\n",
        "        self.task_modulation = nn.Linear(channels // 4, channels)\n",
        "\n",
        "        self.norm = nn.BatchNorm2d(channels)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, task_id=0):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # ä»»å‹™åµŒå…¥èª¿åˆ¶\n",
        "        task_embed = self.task_embeddings[task_id]  # [channels//4]\n",
        "        task_weight = self.task_modulation(task_embed)  # [channels]\n",
        "        task_weight = task_weight.view(1, -1, 1, 1).expand(batch_size, -1, -1, -1)\n",
        "\n",
        "        # é€šé“æ³¨æ„åŠ›\n",
        "        attention = self.channel_attention(x)\n",
        "        x = x * attention\n",
        "\n",
        "        # ä»»å‹™èª¿åˆ¶\n",
        "        x = self.modulation_conv(x)\n",
        "        x = x * task_weight  # ä»»å‹™ç‰¹å®šèª¿åˆ¶\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class UnifiedOutputLayer(nn.Module):\n",
        "    \"\"\"çµ±ä¸€è¼¸å‡ºå±¤ - ä¿®æ­£åˆ†å‰²å°ºå¯¸ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, in_channels=128, det_classes=10, seg_classes=8, cls_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # æª¢æ¸¬è¼¸å‡º\n",
        "        self.det_bbox = nn.Conv2d(in_channels, 4, 1)\n",
        "        self.det_conf = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())\n",
        "        self.det_cls = nn.Sequential(nn.Conv2d(in_channels, det_classes, 1), nn.Sigmoid())\n",
        "\n",
        "        # ä¿®æ­£ï¼šåˆ†å‰²è¼¸å‡º - ç¢ºä¿è¼¸å‡º512x512\n",
        "        self.seg_head = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, 64, 4, 2, 1),  # stride 16->8, 32x32->64x64\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),          # stride 8->4, 64x64->128x128\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(32, 16, 4, 2, 1),          # stride 4->2, 128x128->256x256\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(16, seg_classes, 4, 2, 1)  # stride 2->1, 256x256->512x512\n",
        "        )\n",
        "\n",
        "        # åˆ†é¡è¼¸å‡º\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_channels, cls_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # æª¢æ¸¬è¼¸å‡º\n",
        "        bbox_pred = self.det_bbox(x)\n",
        "        conf_pred = self.det_conf(x)\n",
        "        cls_pred = self.det_cls(x)\n",
        "        detection_output = torch.cat([bbox_pred, conf_pred, cls_pred], dim=1)\n",
        "\n",
        "        # åˆ†å‰²è¼¸å‡º - ç¢ºä¿512x512\n",
        "        segmentation_output = self.seg_head(x)\n",
        "\n",
        "        # å¦‚æœå°ºå¯¸ä¸å°ï¼Œå¼·åˆ¶èª¿æ•´åˆ°512x512\n",
        "        if segmentation_output.size(-1) != 512 or segmentation_output.size(-2) != 512:\n",
        "            segmentation_output = F.interpolate(\n",
        "                segmentation_output,\n",
        "                size=(512, 512),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )\n",
        "\n",
        "        # åˆ†é¡è¼¸å‡º\n",
        "        classification_output = self.cls_head(x)\n",
        "\n",
        "        return {\n",
        "            'detection': detection_output,\n",
        "            'detection_raw': {\n",
        "                'bbox': bbox_pred,\n",
        "                'conf': conf_pred,\n",
        "                'cls': cls_pred\n",
        "            },\n",
        "            'segmentation': segmentation_output,\n",
        "            'classification': classification_output\n",
        "        }\n",
        "\n",
        "# é‡æ–°å‰µå»ºTaskAdaptiveProcessor\n",
        "class TaskAdaptiveProcessor(nn.Module):\n",
        "    \"\"\"ä»»å‹™è‡ªé©æ‡‰è™•ç†å™¨ - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, input_dim=128, det_classes=10, seg_classes=8, cls_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Layer 1: ç‰¹å¾µå¢å¼·å±¤\n",
        "        self.feature_enhancer = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, input_dim, 3, 1, 1),\n",
        "            nn.BatchNorm2d(input_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Layer 2: ä»»å‹™æ„ŸçŸ¥å±¤ (å‰µæ–°æ ¸å¿ƒ)\n",
        "        self.task_awareness = TaskAwarenessLayer(input_dim, num_tasks=3)\n",
        "\n",
        "        # Layer 3: çµ±ä¸€è¼¸å‡ºå±¤ - ä½¿ç”¨ä¿®æ­£ç‰ˆæœ¬\n",
        "        self.output_generator = UnifiedOutputLayer(\n",
        "            input_dim, det_classes, seg_classes, cls_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x, current_task=0):\n",
        "        # Layer 1: ç‰¹å¾µå¢å¼·\n",
        "        x = self.feature_enhancer(x)\n",
        "\n",
        "        # Layer 2: ä»»å‹™æ„ŸçŸ¥è™•ç†\n",
        "        x = self.task_awareness(x, current_task)\n",
        "\n",
        "        # Layer 3: çµ±ä¸€è¼¸å‡º\n",
        "        outputs = self.output_generator(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "print(\"âœ… æ¨¡å‹æ¶æ§‹çµ„ä»¶å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByNDyTxfDs5E",
        "outputId": "a4b50f8f-2ef9-411a-c9c8-be6c55b2c343"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ¨¡å‹æ¶æ§‹çµ„ä»¶å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬äº”æ®µï¼šå®Œæ•´æ¨¡å‹å®šç¾©å’Œåƒæ•¸çµ±è¨ˆ\n",
        "# =============================================================================\n",
        "\n",
        "# é‡æ–°å‰µå»ºå®Œæ•´æ¨¡å‹\n",
        "class UnifiedVisionSystem(nn.Module):\n",
        "    \"\"\"çµ±ä¸€è¦–è¦ºç³»çµ± - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, det_classes=10, seg_classes=8, cls_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Backbone: EfficientNet-B0ç‰¹å¾µæå–å™¨\n",
        "        self.feature_backbone = EfficientNetExtractor('efficientnet-b0', pretrained=True)\n",
        "\n",
        "        # Neck: å‹•æ…‹ç‰¹å¾µèåˆ\n",
        "        self.feature_fusion_neck = DynamicFeatureFusion(\n",
        "            backbone_channels=self.feature_backbone.feature_channels,\n",
        "            output_channels=128\n",
        "        )\n",
        "\n",
        "        # Head: 3å±¤ä»»å‹™è‡ªé©æ‡‰è™•ç†å™¨ - ä½¿ç”¨ä¿®æ­£ç‰ˆæœ¬\n",
        "        self.task_adaptive_head = TaskAdaptiveProcessor(\n",
        "            input_dim=128,\n",
        "            det_classes=det_classes,\n",
        "            seg_classes=seg_classes,\n",
        "            cls_classes=cls_classes\n",
        "        )\n",
        "\n",
        "        # ç•¶å‰ä»»å‹™è¿½è¹¤\n",
        "        self.current_task = 0\n",
        "\n",
        "    def set_task_mode(self, task_name):\n",
        "        \"\"\"è¨­ç½®ç•¶å‰ä»»å‹™æ¨¡å¼\"\"\"\n",
        "        task_mapping = {'segmentation': 0, 'detection': 1, 'classification': 2}\n",
        "        self.current_task = task_mapping.get(task_name, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Backbone: å¤šå°ºåº¦ç‰¹å¾µæå–\n",
        "        backbone_features = self.feature_backbone(x)\n",
        "\n",
        "        # Neck: ç‰¹å¾µèåˆ\n",
        "        fused_features = self.feature_fusion_neck(backbone_features)\n",
        "\n",
        "        # Head: ä»»å‹™è‡ªé©æ‡‰è™•ç†\n",
        "        outputs = self.task_adaptive_head(fused_features, self.current_task)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def get_parameter_count(self):\n",
        "        \"\"\"ç²å–è©³ç´°åƒæ•¸çµ±è¨ˆ\"\"\"\n",
        "        def count_params(module):\n",
        "            return sum(p.numel() for p in module.parameters())\n",
        "\n",
        "        def count_trainable_params(module):\n",
        "            return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "        backbone_total = count_params(self.feature_backbone)\n",
        "        backbone_trainable = count_trainable_params(self.feature_backbone)\n",
        "\n",
        "        neck_total = count_params(self.feature_fusion_neck)\n",
        "        neck_trainable = count_trainable_params(self.feature_fusion_neck)\n",
        "\n",
        "        head_total = count_params(self.task_adaptive_head)\n",
        "        head_trainable = count_trainable_params(self.task_adaptive_head)\n",
        "\n",
        "        total_params = backbone_total + neck_total + head_total\n",
        "        total_trainable = backbone_trainable + neck_trainable + head_trainable\n",
        "\n",
        "        return {\n",
        "            'backbone': {\n",
        "                'total': backbone_total,\n",
        "                'trainable': backbone_trainable,\n",
        "                'total_M': backbone_total / 1e6,\n",
        "                'trainable_M': backbone_trainable / 1e6\n",
        "            },\n",
        "            'neck': {\n",
        "                'total': neck_total,\n",
        "                'trainable': neck_trainable,\n",
        "                'total_M': neck_total / 1e6,\n",
        "                'trainable_M': neck_trainable / 1e6\n",
        "            },\n",
        "            'head': {\n",
        "                'total': head_total,\n",
        "                'trainable': head_trainable,\n",
        "                'total_M': head_total / 1e6,\n",
        "                'trainable_M': head_trainable / 1e6\n",
        "            },\n",
        "            'total': {\n",
        "                'total': total_params,\n",
        "                'trainable': total_trainable,\n",
        "                'total_M': total_params / 1e6,\n",
        "                'trainable_M': total_trainable / 1e6\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def print_model_info(self):\n",
        "        \"\"\"å°å‡ºæ¨¡å‹è©³ç´°è³‡è¨Š\"\"\"\n",
        "        params = self.get_parameter_count()\n",
        "\n",
        "        print(\"ğŸ—ï¸ çµ±ä¸€è¦–è¦ºç³»çµ±æ¶æ§‹è³‡è¨Š\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"ğŸ“± Backbone (EfficientNet-B0):\")\n",
        "        print(f\"   ç¸½åƒæ•¸: {params['backbone']['total_M']:.2f}M\")\n",
        "        print(f\"   å¯è¨“ç·´: {params['backbone']['trainable_M']:.2f}M\")\n",
        "\n",
        "        print(f\"\\nğŸ”— Neck (Dynamic Feature Fusion):\")\n",
        "        print(f\"   ç¸½åƒæ•¸: {params['neck']['total_M']:.2f}M\")\n",
        "        print(f\"   å¯è¨“ç·´: {params['neck']['trainable_M']:.2f}M\")\n",
        "\n",
        "        print(f\"\\nğŸ¯ Head (Task Adaptive Processor):\")\n",
        "        print(f\"   ç¸½åƒæ•¸: {params['head']['total_M']:.2f}M\")\n",
        "        print(f\"   å¯è¨“ç·´: {params['head']['trainable_M']:.2f}M\")\n",
        "\n",
        "        print(f\"\\nğŸ“Š ç¸½è¨ˆ:\")\n",
        "        print(f\"   ç¸½åƒæ•¸: {params['total']['total_M']:.2f}M\")\n",
        "        print(f\"   å¯è¨“ç·´: {params['total']['trainable_M']:.2f}M\")\n",
        "\n",
        "        # æª¢æŸ¥ä½œæ¥­è¦æ±‚\n",
        "        if params['total']['total_M'] < 8.0:\n",
        "            print(f\"âœ… åƒæ•¸é‡ç¬¦åˆè¦æ±‚ (<8M)\")\n",
        "        else:\n",
        "            print(f\"âŒ åƒæ•¸é‡è¶…å‡ºé™åˆ¶ (>8M)\")\n",
        "\n",
        "        return params['total']['total_M'] < 8.0\n",
        "\n",
        "# é‡æ–°å‰µå»ºæ¨¡å‹\n",
        "print(\"ğŸ”„ é‡æ–°å‰µå»ºä¿®æ­£å¾Œçš„æ¨¡å‹...\")\n",
        "\n",
        "# ç²å–é¡åˆ¥è³‡è¨Š\n",
        "category_info = all_loaders['category_info']\n",
        "\n",
        "# å‰µå»ºæ–°æ¨¡å‹\n",
        "model = UnifiedVisionSystem(\n",
        "    det_classes=category_info['detection_classes'],\n",
        "    seg_classes=category_info['segmentation_classes'],\n",
        "    cls_classes=category_info['classification_classes']\n",
        ")\n",
        "\n",
        "# ç§»å‹•åˆ°è¨­å‚™\n",
        "model = model.to(device)\n",
        "\n",
        "# æ¸¬è©¦æ¨¡å‹è¼¸å‡ºå°ºå¯¸\n",
        "print(\"ğŸ§ª æ¸¬è©¦ä¿®æ­£å¾Œçš„æ¨¡å‹...\")\n",
        "test_input = torch.randn(1, 3, 512, 512).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_input)\n",
        "\n",
        "print(\"âœ… è¼¸å‡ºå°ºå¯¸æª¢æŸ¥:\")\n",
        "print(f\"  Detection: {test_outputs['detection'].shape}\")\n",
        "print(f\"  Segmentation: {test_outputs['segmentation'].shape}\")  # æ‡‰è©²æ˜¯ [1, 8, 512, 512]\n",
        "print(f\"  Classification: {test_outputs['classification'].shape}\")\n",
        "\n",
        "# æª¢æŸ¥åƒæ•¸\n",
        "model.print_model_info()\n",
        "\n",
        "print(\"\\nâœ… æ¨¡å‹ä¿®æ­£å®Œæˆï¼Œåˆ†å‰²è¼¸å‡ºå°ºå¯¸å·²å°é½Šåˆ°512x512\")\n",
        "print(\"ğŸš€ ç¾åœ¨å¯ä»¥é‡æ–°åŸ·è¡Œè¨“ç·´æµç¨‹ï¼\")\n",
        "\n",
        "# æ¨¡å‹æ¸¬è©¦å’Œé©—è­‰\n",
        "def test_model_architecture():\n",
        "    \"\"\"æ¸¬è©¦æ¨¡å‹æ¶æ§‹\"\"\"\n",
        "    print(\"ğŸ§ª æ¸¬è©¦æ¨¡å‹æ¶æ§‹...\")\n",
        "\n",
        "    # ç²å–é¡åˆ¥è³‡è¨Š\n",
        "    category_info = all_loaders['category_info']\n",
        "\n",
        "    # å‰µå»ºæ¨¡å‹\n",
        "    model = UnifiedVisionSystem(\n",
        "        det_classes=category_info['detection_classes'],\n",
        "        seg_classes=category_info['segmentation_classes'],\n",
        "        cls_classes=category_info['classification_classes']\n",
        "    )\n",
        "\n",
        "    # ç§»å‹•åˆ°GPU (å¦‚æœå¯ç”¨)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # å°å‡ºæ¨¡å‹è³‡è¨Š\n",
        "    is_valid = model.print_model_info()\n",
        "\n",
        "    # æ¸¬è©¦å‰å‘å‚³æ’­\n",
        "    print(f\"\\nğŸ” æ¸¬è©¦å‰å‘å‚³æ’­...\")\n",
        "    test_input = torch.randn(2, 3, 512, 512).to(device)\n",
        "\n",
        "    try:\n",
        "        # æ¸¬è©¦ä¸åŒä»»å‹™æ¨¡å¼\n",
        "        for task_name in ['segmentation', 'detection', 'classification']:\n",
        "            model.set_task_mode(task_name)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(test_input)\n",
        "\n",
        "            print(f\"âœ… {task_name.capitalize()} æ¨¡å¼:\")\n",
        "            print(f\"   Detection: {outputs['detection'].shape}\")\n",
        "            print(f\"   Segmentation: {outputs['segmentation'].shape}\")\n",
        "            print(f\"   Classification: {outputs['classification'].shape}\")\n",
        "\n",
        "        print(\"\\nğŸ‰ æ¨¡å‹æ¶æ§‹æ¸¬è©¦æˆåŠŸï¼\")\n",
        "        return model, is_valid\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, False\n",
        "\n",
        "# æ¨è«–é€Ÿåº¦æ¸¬è©¦\n",
        "def test_inference_speed(model, num_tests=10):\n",
        "    \"\"\"æ¸¬è©¦æ¨è«–é€Ÿåº¦\"\"\"\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    print(f\"\\nâ±ï¸ æ¸¬è©¦æ¨è«–é€Ÿåº¦ ({num_tests}æ¬¡å¹³å‡)...\")\n",
        "    model.eval()\n",
        "\n",
        "    test_input = torch.randn(1, 3, 512, 512).to(device)\n",
        "\n",
        "    # æš–èº«\n",
        "    for _ in range(3):\n",
        "        with torch.no_grad():\n",
        "            _ = model(test_input)\n",
        "\n",
        "    # æ­£å¼æ¸¬è©¦\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(num_tests):\n",
        "        with torch.no_grad():\n",
        "            _ = model(test_input)\n",
        "\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_time = (end_time - start_time) / num_tests * 1000  # æ¯«ç§’\n",
        "\n",
        "    print(f\"å¹³å‡æ¨è«–æ™‚é–“: {avg_time:.2f}ms\")\n",
        "\n",
        "    if avg_time <= 150:\n",
        "        print(\"âœ… æ¨è«–é€Ÿåº¦ç¬¦åˆè¦æ±‚ (â‰¤150ms)\")\n",
        "    else:\n",
        "        print(\"âŒ æ¨è«–é€Ÿåº¦è¶…å‡ºé™åˆ¶ (>150ms)\")\n",
        "\n",
        "    return avg_time <= 150\n",
        "\n",
        "# åŸ·è¡Œæ¨¡å‹æ¸¬è©¦\n",
        "model, model_valid = test_model_architecture()\n",
        "\n",
        "if model and model_valid:\n",
        "    print(\"\\nâœ… æ¨¡å‹å‰µå»ºæˆåŠŸï¼Œç¬¦åˆä½œæ¥­è¦æ±‚\")\n",
        "    speed_valid = test_inference_speed(model)\n",
        "    print(f\"\\nğŸ† æ•´é«”è©•ä¼°: {'âœ… é€šé' if model_valid and speed_valid else 'âŒ éœ€è¦èª¿æ•´'}\")\n",
        "else:\n",
        "    print(\"\\nâŒ æ¨¡å‹å‰µå»ºå¤±æ•—æˆ–ä¸ç¬¦åˆè¦æ±‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s26ni8jODuDx",
        "outputId": "41676534-d1c8-4de9-8089-923c2b9c2e3c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ é‡æ–°å‰µå»ºä¿®æ­£å¾Œçš„æ¨¡å‹...\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "âœ… EfficientNet-B0 è¼‰å…¥å®Œæˆ\n",
            "ğŸ“Š ç‰¹å¾µé€šé“æ•¸: {'p3': 24, 'p4': 80, 'p5': 112}\n",
            "ç¸½åƒæ•¸: 4.01M, å¯è¨“ç·´: 3.70M\n",
            "âœ… ç‰¹å¾µèåˆå±¤å‰µå»º: P3(24)â†’128, P4(80)â†’128\n",
            "ğŸ§ª æ¸¬è©¦ä¿®æ­£å¾Œçš„æ¨¡å‹...\n",
            "âœ… è¼¸å‡ºå°ºå¯¸æª¢æŸ¥:\n",
            "  Detection: torch.Size([1, 15, 64, 64])\n",
            "  Segmentation: torch.Size([1, 8, 512, 512])\n",
            "  Classification: torch.Size([1, 10])\n",
            "ğŸ—ï¸ çµ±ä¸€è¦–è¦ºç³»çµ±æ¶æ§‹è³‡è¨Š\n",
            "==================================================\n",
            "ğŸ“± Backbone (EfficientNet-B0):\n",
            "   ç¸½åƒæ•¸: 4.01M\n",
            "   å¯è¨“ç·´: 3.70M\n",
            "\n",
            "ğŸ”— Neck (Dynamic Feature Fusion):\n",
            "   ç¸½åƒæ•¸: 0.16M\n",
            "   å¯è¨“ç·´: 0.16M\n",
            "\n",
            "ğŸ¯ Head (Task Adaptive Processor):\n",
            "   ç¸½åƒæ•¸: 0.48M\n",
            "   å¯è¨“ç·´: 0.48M\n",
            "\n",
            "ğŸ“Š ç¸½è¨ˆ:\n",
            "   ç¸½åƒæ•¸: 4.65M\n",
            "   å¯è¨“ç·´: 4.34M\n",
            "âœ… åƒæ•¸é‡ç¬¦åˆè¦æ±‚ (<8M)\n",
            "\n",
            "âœ… æ¨¡å‹ä¿®æ­£å®Œæˆï¼Œåˆ†å‰²è¼¸å‡ºå°ºå¯¸å·²å°é½Šåˆ°512x512\n",
            "ğŸš€ ç¾åœ¨å¯ä»¥é‡æ–°åŸ·è¡Œè¨“ç·´æµç¨‹ï¼\n",
            "ğŸ§ª æ¸¬è©¦æ¨¡å‹æ¶æ§‹...\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "âœ… EfficientNet-B0 è¼‰å…¥å®Œæˆ\n",
            "ğŸ“Š ç‰¹å¾µé€šé“æ•¸: {'p3': 24, 'p4': 80, 'p5': 112}\n",
            "ç¸½åƒæ•¸: 4.01M, å¯è¨“ç·´: 3.70M\n",
            "âœ… ç‰¹å¾µèåˆå±¤å‰µå»º: P3(24)â†’128, P4(80)â†’128\n",
            "ğŸ—ï¸ çµ±ä¸€è¦–è¦ºç³»çµ±æ¶æ§‹è³‡è¨Š\n",
            "==================================================\n",
            "ğŸ“± Backbone (EfficientNet-B0):\n",
            "   ç¸½åƒæ•¸: 4.01M\n",
            "   å¯è¨“ç·´: 3.70M\n",
            "\n",
            "ğŸ”— Neck (Dynamic Feature Fusion):\n",
            "   ç¸½åƒæ•¸: 0.16M\n",
            "   å¯è¨“ç·´: 0.16M\n",
            "\n",
            "ğŸ¯ Head (Task Adaptive Processor):\n",
            "   ç¸½åƒæ•¸: 0.48M\n",
            "   å¯è¨“ç·´: 0.48M\n",
            "\n",
            "ğŸ“Š ç¸½è¨ˆ:\n",
            "   ç¸½åƒæ•¸: 4.65M\n",
            "   å¯è¨“ç·´: 4.34M\n",
            "âœ… åƒæ•¸é‡ç¬¦åˆè¦æ±‚ (<8M)\n",
            "\n",
            "ğŸ” æ¸¬è©¦å‰å‘å‚³æ’­...\n",
            "âœ… Segmentation æ¨¡å¼:\n",
            "   Detection: torch.Size([2, 15, 64, 64])\n",
            "   Segmentation: torch.Size([2, 8, 512, 512])\n",
            "   Classification: torch.Size([2, 10])\n",
            "âœ… Detection æ¨¡å¼:\n",
            "   Detection: torch.Size([2, 15, 64, 64])\n",
            "   Segmentation: torch.Size([2, 8, 512, 512])\n",
            "   Classification: torch.Size([2, 10])\n",
            "âœ… Classification æ¨¡å¼:\n",
            "   Detection: torch.Size([2, 15, 64, 64])\n",
            "   Segmentation: torch.Size([2, 8, 512, 512])\n",
            "   Classification: torch.Size([2, 10])\n",
            "\n",
            "ğŸ‰ æ¨¡å‹æ¶æ§‹æ¸¬è©¦æˆåŠŸï¼\n",
            "\n",
            "âœ… æ¨¡å‹å‰µå»ºæˆåŠŸï¼Œç¬¦åˆä½œæ¥­è¦æ±‚\n",
            "\n",
            "â±ï¸ æ¸¬è©¦æ¨è«–é€Ÿåº¦ (10æ¬¡å¹³å‡)...\n",
            "å¹³å‡æ¨è«–æ™‚é–“: 16.99ms\n",
            "âœ… æ¨è«–é€Ÿåº¦ç¬¦åˆè¦æ±‚ (â‰¤150ms)\n",
            "\n",
            "ğŸ† æ•´é«”è©•ä¼°: âœ… é€šé\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬å…­æ®µï¼šæå¤±å‡½æ•¸å’Œè©•ä¼°æŒ‡æ¨™\n",
        "# =============================================================================\n",
        "\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "\n",
        "# æ™ºèƒ½åˆ†å‰²æå¤±å‡½æ•¸\n",
        "class IntelligentSegmentationLoss(nn.Module):\n",
        "    \"\"\"æ™ºèƒ½åˆ†å‰²æå¤±å‡½æ•¸ - å‰µæ–°ï¼šè‡ªé©æ‡‰é¡åˆ¥æ¬Šé‡\"\"\"\n",
        "    def __init__(self, num_classes=8, ignore_index=255, use_focal=True):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.ignore_index = ignore_index\n",
        "        self.use_focal = use_focal\n",
        "\n",
        "        # å‰µæ–°ï¼šå‹•æ…‹é¡åˆ¥æ¬Šé‡è¨ˆç®—\n",
        "        self.class_weight_calculator = DynamicClassWeightCalculator(num_classes)\n",
        "\n",
        "        # Focal Lossåƒæ•¸\n",
        "        self.focal_alpha = 0.25\n",
        "        self.focal_gamma = 2.0\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # ç²å–å‹•æ…‹æ¬Šé‡\n",
        "        class_weights = self.class_weight_calculator.compute_weights(targets)\n",
        "\n",
        "        if self.use_focal:\n",
        "            return self._focal_loss_with_weights(predictions, targets, class_weights)\n",
        "        else:\n",
        "            ce_loss = F.cross_entropy(\n",
        "                predictions, targets,\n",
        "                weight=class_weights,\n",
        "                ignore_index=self.ignore_index\n",
        "            )\n",
        "            return ce_loss\n",
        "\n",
        "    def _focal_loss_with_weights(self, pred, target, weights):\n",
        "        \"\"\"åŠ æ¬ŠFocal Loss\"\"\"\n",
        "        # è¨ˆç®—äº¤å‰ç†µ\n",
        "        ce_loss = F.cross_entropy(\n",
        "            pred, target,\n",
        "            weight=weights,\n",
        "            ignore_index=self.ignore_index,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        # Focalèª¿æ•´\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.focal_alpha * (1 - pt) ** self.focal_gamma * ce_loss\n",
        "\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# å‹•æ…‹é¡åˆ¥æ¬Šé‡è¨ˆç®—å™¨\n",
        "class DynamicClassWeightCalculator:\n",
        "    \"\"\"å‹•æ…‹é¡åˆ¥æ¬Šé‡è¨ˆç®—å™¨\"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "        self.weight_cache = {}\n",
        "\n",
        "    def compute_weights(self, targets):\n",
        "        \"\"\"æ ¹æ“šç•¶å‰batchå‹•æ…‹è¨ˆç®—æ¬Šé‡\"\"\"\n",
        "        device = targets.device\n",
        "\n",
        "        # çµ±è¨ˆç•¶å‰batchçš„é¡åˆ¥åˆ†å¸ƒ\n",
        "        class_counts = torch.zeros(self.num_classes, device=device)\n",
        "\n",
        "        for class_id in range(self.num_classes):\n",
        "            count = (targets == class_id).sum().float()\n",
        "            class_counts[class_id] = count\n",
        "\n",
        "        # é¿å…é™¤é›¶\n",
        "        class_counts = torch.clamp(class_counts, min=1.0)\n",
        "\n",
        "        # è¨ˆç®—é€†é »ç‡æ¬Šé‡\n",
        "        total_pixels = class_counts.sum()\n",
        "        class_weights = total_pixels / (self.num_classes * class_counts)\n",
        "\n",
        "        # æ­¸ä¸€åŒ–\n",
        "        class_weights = class_weights / class_weights.mean()\n",
        "\n",
        "        return class_weights\n",
        "\n",
        "# ä¿®æ­£IntelligentDetectionLossé¡\n",
        "class IntelligentDetectionLoss(nn.Module):\n",
        "    \"\"\"æ™ºèƒ½æª¢æ¸¬æå¤±å‡½æ•¸ - ä¿®æ­£é®ç½©å½¢ç‹€ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, num_classes=10, lambda_coord=5.0, lambda_obj=1.0, lambda_noobj=0.5):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.lambda_coord = lambda_coord\n",
        "        self.lambda_obj = lambda_obj\n",
        "        self.lambda_noobj = lambda_noobj\n",
        "\n",
        "        # å‰µæ–°ï¼šè‡ªé©æ‡‰æ¬Šé‡èª¿æ•´å™¨\n",
        "        self.adaptive_balancer = AdaptiveLossBalancer()\n",
        "\n",
        "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
        "        self.bce_loss = nn.BCELoss(reduction='sum')\n",
        "\n",
        "    def forward(self, predictions, target_boxes, target_conf, target_cls):\n",
        "        batch_size = predictions['bbox'].size(0)\n",
        "        device = predictions['bbox'].device\n",
        "\n",
        "        # é æ¸¬å€¼\n",
        "        pred_boxes = predictions['bbox']\n",
        "        pred_conf = predictions['conf']\n",
        "        pred_cls = predictions['cls']\n",
        "\n",
        "        # ä¿®æ­£ï¼šç¢ºä¿æ‰€æœ‰tensorå½¢ç‹€åŒ¹é…\n",
        "        # ç§»é™¤å¤šé¤˜çš„ç¶­åº¦ä¸¦ç¢ºä¿ä¸€è‡´æ€§\n",
        "        if target_conf.dim() == 4 and target_conf.size(1) == 1:\n",
        "            target_conf = target_conf.squeeze(1)  # [B, 1, H, W] -> [B, H, W]\n",
        "\n",
        "        if pred_conf.dim() == 4 and pred_conf.size(1) == 1:\n",
        "            pred_conf = pred_conf.squeeze(1)    # [B, 1, H, W] -> [B, H, W]\n",
        "\n",
        "        # ç‰©ä»¶é®ç½© - ä¿®æ­£å½¢ç‹€\n",
        "        obj_mask = target_conf > 0.5  # [B, H, W]\n",
        "        noobj_mask = ~obj_mask        # [B, H, W]\n",
        "\n",
        "        # åº§æ¨™æå¤± (åªè¨ˆç®—æœ‰ç‰©ä»¶çš„ä½ç½®)\n",
        "        if obj_mask.sum() > 0:\n",
        "            # å°‡ç©ºé–“ç¶­åº¦å±•å¹³é€²è¡Œç´¢å¼•\n",
        "            pred_boxes_flat = pred_boxes.permute(0, 2, 3, 1).contiguous()  # [B, H, W, 4]\n",
        "            target_boxes_flat = target_boxes.permute(0, 2, 3, 1).contiguous()  # [B, H, W, 4]\n",
        "\n",
        "            pred_boxes_obj = pred_boxes_flat[obj_mask]  # [N, 4]\n",
        "            target_boxes_obj = target_boxes_flat[obj_mask]  # [N, 4]\n",
        "\n",
        "            coord_loss = self.mse_loss(pred_boxes_obj, target_boxes_obj) / batch_size\n",
        "        else:\n",
        "            coord_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
        "\n",
        "        # ç½®ä¿¡åº¦æå¤± - ä¿®æ­£å½¢ç‹€\n",
        "        # ç¢ºä¿pred_confå’Œtarget_confå½¢ç‹€ä¸€è‡´\n",
        "        if pred_conf.shape != target_conf.shape:\n",
        "            if pred_conf.dim() == 4 and pred_conf.size(1) == 1:\n",
        "                pred_conf = pred_conf.squeeze(1)\n",
        "            if target_conf.dim() == 3:\n",
        "                target_conf = target_conf.float()\n",
        "\n",
        "        # é‡æ–°å®šç¾©ç½®ä¿¡åº¦ç›®æ¨™ï¼Œç¢ºä¿å½¢ç‹€ä¸€è‡´\n",
        "        target_conf_float = target_conf.float()\n",
        "\n",
        "        obj_conf_loss = self.bce_loss(pred_conf[obj_mask], target_conf_float[obj_mask]) / batch_size\n",
        "        noobj_conf_loss = self.bce_loss(pred_conf[noobj_mask], target_conf_float[noobj_mask]) / batch_size\n",
        "\n",
        "        # é¡åˆ¥æå¤± (åªè¨ˆç®—æœ‰ç‰©ä»¶çš„ä½ç½®)\n",
        "        if obj_mask.sum() > 0:\n",
        "            pred_cls_flat = pred_cls.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
        "            target_cls_flat = target_cls.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
        "\n",
        "            pred_cls_obj = pred_cls_flat[obj_mask]  # [N, C]\n",
        "            target_cls_obj = target_cls_flat[obj_mask]  # [N, C]\n",
        "\n",
        "            cls_loss = self.bce_loss(pred_cls_obj, target_cls_obj.float()) / batch_size\n",
        "        else:\n",
        "            cls_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
        "\n",
        "        # å‰µæ–°ï¼šè‡ªé©æ‡‰æ¬Šé‡å¹³è¡¡\n",
        "        weights = self.adaptive_balancer.get_adaptive_weights(\n",
        "            coord_loss, obj_conf_loss, noobj_conf_loss, cls_loss\n",
        "        )\n",
        "\n",
        "        total_loss = (weights['coord'] * self.lambda_coord * coord_loss +\n",
        "                     weights['obj'] * self.lambda_obj * obj_conf_loss +\n",
        "                     weights['noobj'] * self.lambda_noobj * noobj_conf_loss +\n",
        "                     weights['cls'] * cls_loss)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# è‡ªé©æ‡‰æå¤±å¹³è¡¡å™¨\n",
        "class AdaptiveLossBalancer:\n",
        "    \"\"\"è‡ªé©æ‡‰æå¤±å¹³è¡¡å™¨\"\"\"\n",
        "    def __init__(self, momentum=0.9):\n",
        "        self.momentum = momentum\n",
        "        self.loss_history = {}\n",
        "\n",
        "    def get_adaptive_weights(self, coord_loss, obj_loss, noobj_loss, cls_loss):\n",
        "        \"\"\"è¨ˆç®—è‡ªé©æ‡‰æ¬Šé‡\"\"\"\n",
        "        current_losses = {\n",
        "            'coord': coord_loss.item(),\n",
        "            'obj': obj_loss.item(),\n",
        "            'noobj': noobj_loss.item(),\n",
        "            'cls': cls_loss.item()\n",
        "        }\n",
        "\n",
        "        # æ›´æ–°æå¤±æ­·å²\n",
        "        if not self.loss_history:\n",
        "            self.loss_history = current_losses.copy()\n",
        "        else:\n",
        "            for key in current_losses:\n",
        "                self.loss_history[key] = (self.momentum * self.loss_history[key] +\n",
        "                                        (1 - self.momentum) * current_losses[key])\n",
        "\n",
        "        # è¨ˆç®—è‡ªé©æ‡‰æ¬Šé‡ (è¼ƒå¤§çš„æå¤±ç²å¾—è¼ƒå°çš„æ¬Šé‡)\n",
        "        total_loss = sum(self.loss_history.values())\n",
        "        weights = {}\n",
        "\n",
        "        for key in self.loss_history:\n",
        "            if total_loss > 0:\n",
        "                # é€†æ¯”ä¾‹æ¬Šé‡\n",
        "                weights[key] = 1.0 / (1.0 + self.loss_history[key] / total_loss)\n",
        "            else:\n",
        "                weights[key] = 1.0\n",
        "\n",
        "        # æ­¸ä¸€åŒ–\n",
        "        weight_sum = sum(weights.values())\n",
        "        for key in weights:\n",
        "            weights[key] = weights[key] / weight_sum * len(weights)\n",
        "\n",
        "        return weights\n",
        "\n",
        "# åˆ†é¡æå¤±å‡½æ•¸\n",
        "class ClassificationLoss(nn.Module):\n",
        "    \"\"\"åˆ†é¡æå¤±å‡½æ•¸ - æ¨™æº–äº¤å‰ç†µ\"\"\"\n",
        "    def __init__(self, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        return self.criterion(predictions, targets)\n",
        "\n",
        "# ä¿®æ­£MetricsCalculatoré¡ä¸­çš„mAPè¨ˆç®—\n",
        "class MetricsCalculator:\n",
        "    \"\"\"è©•ä¼°æŒ‡æ¨™è¨ˆç®—å™¨ - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_miou(predictions, targets, num_classes=8, ignore_index=255):\n",
        "        \"\"\"è¨ˆç®—mIoU\"\"\"\n",
        "        pred_classes = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        ious = []\n",
        "        for class_id in range(num_classes):\n",
        "            pred_mask = (pred_classes == class_id)\n",
        "            target_mask = (targets == class_id)\n",
        "\n",
        "            # æ’é™¤ignore_index\n",
        "            valid_mask = (targets != ignore_index)\n",
        "            pred_mask = pred_mask & valid_mask\n",
        "            target_mask = target_mask & valid_mask\n",
        "\n",
        "            intersection = (pred_mask & target_mask).sum().float()\n",
        "            union = (pred_mask | target_mask).sum().float()\n",
        "\n",
        "            if union > 0:\n",
        "                ious.append((intersection / union).item())\n",
        "            else:\n",
        "                ious.append(0.0)\n",
        "\n",
        "        return np.mean(ious) if ious else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_detection_map(pred_boxes, pred_conf, pred_cls, gt_boxes, gt_labels,\n",
        "                              conf_threshold=0.3, max_detections=50):\n",
        "        \"\"\"è¨ˆç®—æª¢æ¸¬mAP - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            batch_size = pred_boxes.size(0)\n",
        "            total_tp = 0\n",
        "            total_fp = 0\n",
        "            total_gt = 0\n",
        "\n",
        "            for b in range(batch_size):\n",
        "                # ä¿®æ­£ï¼šå®‰å…¨è™•ç†gt_boxeså’Œgt_labels\n",
        "                if isinstance(gt_boxes, list) and b < len(gt_boxes):\n",
        "                    gt_box = gt_boxes[b]\n",
        "                elif isinstance(gt_boxes, torch.Tensor):\n",
        "                    gt_box = gt_boxes[b] if b < gt_boxes.size(0) else torch.empty(0, 4)\n",
        "                else:\n",
        "                    gt_box = torch.empty(0, 4)\n",
        "\n",
        "                if isinstance(gt_labels, list) and b < len(gt_labels):\n",
        "                    gt_lab = gt_labels[b]\n",
        "                elif isinstance(gt_labels, torch.Tensor):\n",
        "                    gt_lab = gt_labels[b] if b < gt_labels.size(0) else torch.empty(0)\n",
        "                else:\n",
        "                    gt_lab = torch.empty(0)\n",
        "\n",
        "                # æª¢æŸ¥æ˜¯å¦ç‚ºç©º\n",
        "                if (isinstance(gt_box, torch.Tensor) and len(gt_box) == 0) or \\\n",
        "                   (isinstance(gt_lab, torch.Tensor) and len(gt_lab) == 0):\n",
        "                    continue\n",
        "\n",
        "                # ç¢ºä¿åœ¨æ­£ç¢ºè¨­å‚™ä¸Š\n",
        "                if hasattr(gt_box, 'to'):\n",
        "                    gt_box = gt_box.to(pred_boxes.device)\n",
        "                if hasattr(gt_lab, 'to'):\n",
        "                    gt_lab = gt_lab.to(pred_boxes.device)\n",
        "\n",
        "                # è¨ˆç®—GTæ•¸é‡\n",
        "                if isinstance(gt_lab, torch.Tensor):\n",
        "                    total_gt += len(gt_lab)\n",
        "                elif hasattr(gt_lab, '__len__'):\n",
        "                    total_gt += len(gt_lab)\n",
        "                else:\n",
        "                    total_gt += 1\n",
        "\n",
        "                # ç²å–é æ¸¬\n",
        "                conf_pred = pred_conf[b]\n",
        "                if conf_pred.dim() == 3:  # [1, H, W]\n",
        "                    conf_pred = conf_pred.squeeze(0)  # [H, W]\n",
        "\n",
        "                cls_pred = pred_cls[b]  # [C, H, W]\n",
        "\n",
        "                # æ‰¾åˆ°é«˜ç½®ä¿¡åº¦é æ¸¬\n",
        "                high_conf_mask = conf_pred > conf_threshold\n",
        "                if not high_conf_mask.any():\n",
        "                    continue\n",
        "\n",
        "                # ç²å–é æ¸¬ä½ç½®\n",
        "                high_conf_positions = torch.nonzero(high_conf_mask, as_tuple=False)\n",
        "                max_check = min(max_detections, len(high_conf_positions))\n",
        "\n",
        "                # ä¿®æ­£ï¼šå®‰å…¨ç²å–GTé¡åˆ¥é›†åˆ\n",
        "                try:\n",
        "                    if isinstance(gt_lab, torch.Tensor):\n",
        "                        if gt_lab.dim() == 0:\n",
        "                            gt_classes = {gt_lab.item()}\n",
        "                        else:\n",
        "                            gt_classes = set(gt_lab.cpu().numpy().tolist())\n",
        "                    elif isinstance(gt_lab, (list, tuple)):\n",
        "                        gt_classes = set(gt_lab)\n",
        "                    elif isinstance(gt_lab, (int, float)):\n",
        "                        gt_classes = {int(gt_lab)}\n",
        "                    else:\n",
        "                        gt_classes = set()\n",
        "                except Exception as e:\n",
        "                    print(f\"GTé¡åˆ¥è™•ç†éŒ¯èª¤: {e}\")\n",
        "                    continue\n",
        "\n",
        "                for i in range(max_check):\n",
        "                    y, x = high_conf_positions[i]\n",
        "\n",
        "                    # ç²å–é æ¸¬é¡åˆ¥\n",
        "                    cls_scores = cls_pred[:, y, x]\n",
        "                    pred_class = torch.argmax(cls_scores).item()\n",
        "\n",
        "                    # æª¢æŸ¥é¡åˆ¥åŒ¹é…\n",
        "                    if pred_class in gt_classes:\n",
        "                        total_tp += 1\n",
        "                    else:\n",
        "                        total_fp += 1\n",
        "\n",
        "            # è¨ˆç®—æŒ‡æ¨™\n",
        "            if total_tp + total_fp == 0:\n",
        "                return 0.0\n",
        "\n",
        "            precision = total_tp / (total_tp + total_fp)\n",
        "            recall = total_tp / max(total_gt, 1)\n",
        "\n",
        "            if precision + recall > 0:\n",
        "                f1_score = 2 * precision * recall / (precision + recall)\n",
        "                return f1_score * 0.5  # ç°¡åŒ–çš„mAPè¿‘ä¼¼\n",
        "            else:\n",
        "                return 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"mAPè¨ˆç®—éŒ¯èª¤: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_accuracy(predictions, targets):\n",
        "        \"\"\"è¨ˆç®—åˆ†é¡æº–ç¢ºç‡\"\"\"\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        total = targets.size(0)\n",
        "        correct = (predicted == targets).sum().item()\n",
        "        return 100.0 * correct / total\n",
        "\n",
        "# ä¿®æ­£TargetAssigneré¡\n",
        "class TargetAssigner:\n",
        "    \"\"\"ç›®æ¨™åˆ†é…å™¨ - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, grid_size=32):\n",
        "        self.grid_size = grid_size\n",
        "\n",
        "    def assign_targets(self, pred_shape, gt_boxes, gt_labels):\n",
        "        \"\"\"åˆ†é…æª¢æ¸¬ç›®æ¨™ - ä¿®æ­£å½¢ç‹€å•é¡Œ\"\"\"\n",
        "        batch_size, channels, height, width = pred_shape\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # åˆå§‹åŒ–ç›®æ¨™å¼µé‡ - ç¢ºä¿æ­£ç¢ºå½¢ç‹€\n",
        "        target_boxes = torch.zeros(batch_size, 4, height, width, device=device)\n",
        "        target_conf = torch.zeros(batch_size, height, width, device=device)  # ç§»é™¤é€šé“ç¶­åº¦\n",
        "        target_cls = torch.zeros(batch_size, channels-5, height, width, device=device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            if b >= len(gt_boxes) or len(gt_boxes[b]) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = gt_boxes[b].to(device).float()\n",
        "            labels = gt_labels[b].to(device).long()\n",
        "\n",
        "            # è½‰æ›åˆ°ç¶²æ ¼åº§æ¨™\n",
        "            boxes_grid = boxes.clone()\n",
        "            boxes_grid[:, :2] *= height  # ä½¿ç”¨å¯¦éš›ç¶²æ ¼å¤§å°\n",
        "            boxes_grid[:, 2:] *= height\n",
        "\n",
        "            for box, label in zip(boxes_grid, labels):\n",
        "                cx, cy, w, h = box\n",
        "\n",
        "                # æ‰¾åˆ°ç¶²æ ¼ä½ç½®\n",
        "                gi = int(torch.clamp(cx, 0, width - 1))\n",
        "                gj = int(torch.clamp(cy, 0, height - 1))\n",
        "\n",
        "                # ç›¸å°ä½ç½®\n",
        "                dx = cx - gi\n",
        "                dy = cy - gj\n",
        "\n",
        "                # é˜²æ­¢log(0)\n",
        "                w = torch.clamp(w, min=1e-6)\n",
        "                h = torch.clamp(h, min=1e-6)\n",
        "\n",
        "                # åˆ†é…ç›®æ¨™\n",
        "                target_boxes[b, :, gj, gi] = torch.tensor([dx, dy, w.log(), h.log()], device=device)\n",
        "                target_conf[b, gj, gi] = 1.0  # ä¿®æ­£ï¼šç§»é™¤é€šé“ç¶­åº¦\n",
        "\n",
        "                # é¡åˆ¥æ¨™ç±¤\n",
        "                if label < target_cls.size(1):\n",
        "                    target_cls[b, label, gj, gi] = 1.0\n",
        "\n",
        "        return target_boxes, target_conf, target_cls\n",
        "\n",
        "print(\"âœ… æå¤±å‡½æ•¸å’Œè©•ä¼°æŒ‡æ¨™å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_5jBewCFIqt",
        "outputId": "834f00ff-76ca-435f-baad-3955ee7e2441"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æå¤±å‡½æ•¸å’Œè©•ä¼°æŒ‡æ¨™å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬ä¸ƒæ®µï¼šçŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶\n",
        "# =============================================================================\n",
        "\n",
        "# ä¿®æ­£ProgressiveKnowledgeDistillationé¡\n",
        "class ProgressiveKnowledgeDistillation(nn.Module):\n",
        "    \"\"\"æ¼¸é€²å¼çŸ¥è­˜è’¸é¤¾ - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, temperature_schedule=[2.0, 3.0, 4.0], alpha_schedule=[0.7, 0.8, 0.75]):\n",
        "        super().__init__()\n",
        "        self.temperature_schedule = temperature_schedule\n",
        "        self.alpha_schedule = alpha_schedule\n",
        "        self.current_stage = 0\n",
        "\n",
        "        # å‰µæ–°ï¼šæº«åº¦èª¿åº¦å™¨\n",
        "        self.temperature_scheduler = TemperatureScheduler(temperature_schedule)\n",
        "\n",
        "        # ä»»å‹™ç‰¹å®šè’¸é¤¾æ¬Šé‡\n",
        "        self.task_distillation_weights = TaskSpecificDistillationWeights()\n",
        "\n",
        "        # KLæ•£åº¦æå¤±\n",
        "        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def set_stage(self, stage):\n",
        "        \"\"\"è¨­ç½®ç•¶å‰è¨“ç·´éšæ®µ\"\"\"\n",
        "        self.current_stage = min(stage, len(self.temperature_schedule) - 1)\n",
        "        self.temperature_scheduler.set_stage(stage)\n",
        "\n",
        "    def forward(self, student_outputs, teacher_outputs, hard_targets, task_type):\n",
        "        \"\"\"åŸ·è¡ŒçŸ¥è­˜è’¸é¤¾\"\"\"\n",
        "        if teacher_outputs is None:\n",
        "            # ç¬¬ä¸€éšæ®µç„¡æ•™å¸«æ¨¡å‹\n",
        "            return self._compute_hard_loss(student_outputs, hard_targets, task_type)\n",
        "\n",
        "        # ç²å–ç•¶å‰éšæ®µåƒæ•¸\n",
        "        temperature = self.temperature_schedule[self.current_stage]\n",
        "        alpha = self.alpha_schedule[self.current_stage]\n",
        "\n",
        "        # è¨ˆç®—ç¡¬æå¤±\n",
        "        hard_loss = self._compute_hard_loss(student_outputs, hard_targets, task_type)\n",
        "\n",
        "        # è¨ˆç®—è»Ÿæå¤±\n",
        "        soft_loss = self._compute_soft_loss(student_outputs, teacher_outputs,\n",
        "                                          temperature, task_type)\n",
        "\n",
        "        # ä»»å‹™ç‰¹å®šæ¬Šé‡èª¿æ•´\n",
        "        task_weight = self.task_distillation_weights.get_weight(task_type)\n",
        "\n",
        "        # çµ„åˆæå¤±\n",
        "        total_loss = alpha * soft_loss * task_weight + (1 - alpha) * hard_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def _compute_hard_loss(self, student_outputs, targets, task_type):\n",
        "        \"\"\"è¨ˆç®—ç¡¬æ¨™ç±¤æå¤± - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "        if task_type == 'segmentation':\n",
        "            # ä¿®æ­£ï¼šç¢ºä¿å‚³å…¥æ­£ç¢ºçš„å¼µé‡\n",
        "            if isinstance(student_outputs, dict):\n",
        "                seg_output = student_outputs['segmentation']\n",
        "            else:\n",
        "                seg_output = student_outputs\n",
        "\n",
        "            criterion = IntelligentSegmentationLoss(use_focal=True)\n",
        "            return criterion(seg_output, targets)\n",
        "\n",
        "        elif task_type == 'detection':\n",
        "            if isinstance(student_outputs, dict):\n",
        "                det_raw = student_outputs['detection_raw']\n",
        "            else:\n",
        "                det_raw = student_outputs\n",
        "\n",
        "            criterion = IntelligentDetectionLoss()\n",
        "            return criterion(det_raw, targets['boxes'], targets['conf'], targets['cls'])\n",
        "\n",
        "        elif task_type == 'classification':\n",
        "            if isinstance(student_outputs, dict):\n",
        "                cls_output = student_outputs['classification']\n",
        "            else:\n",
        "                cls_output = student_outputs\n",
        "\n",
        "            criterion = ClassificationLoss(label_smoothing=0.1)\n",
        "            return criterion(cls_output, targets)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"æœªçŸ¥ä»»å‹™é¡å‹: {task_type}\")\n",
        "\n",
        "    def _compute_soft_loss(self, student_outputs, teacher_outputs, temperature, task_type):\n",
        "        \"\"\"è¨ˆç®—è»Ÿæ¨™ç±¤æå¤± - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "        if task_type == 'segmentation':\n",
        "            student_logits = student_outputs['segmentation'] if isinstance(student_outputs, dict) else student_outputs\n",
        "            teacher_logits = teacher_outputs['segmentation'] if isinstance(teacher_outputs, dict) else teacher_outputs\n",
        "            return self._segmentation_kd_loss(student_logits, teacher_logits, temperature)\n",
        "\n",
        "        elif task_type == 'detection':\n",
        "            student_raw = student_outputs['detection_raw'] if isinstance(student_outputs, dict) else student_outputs\n",
        "            teacher_raw = teacher_outputs['detection_raw'] if isinstance(teacher_outputs, dict) else teacher_outputs\n",
        "            return self._detection_kd_loss(student_raw, teacher_raw, temperature)\n",
        "\n",
        "        elif task_type == 'classification':\n",
        "            student_logits = student_outputs['classification'] if isinstance(student_outputs, dict) else student_outputs\n",
        "            teacher_logits = teacher_outputs['classification'] if isinstance(teacher_outputs, dict) else teacher_outputs\n",
        "            return self._classification_kd_loss(student_logits, teacher_logits, temperature)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"æœªçŸ¥ä»»å‹™é¡å‹: {task_type}\")\n",
        "\n",
        "    def _segmentation_kd_loss(self, student_logits, teacher_logits, temperature):\n",
        "        \"\"\"åˆ†å‰²ä»»å‹™çŸ¥è­˜è’¸é¤¾\"\"\"\n",
        "        # æ‡‰ç”¨æº«åº¦\n",
        "        student_soft = F.log_softmax(student_logits / temperature, dim=1)\n",
        "        teacher_soft = F.softmax(teacher_logits / temperature, dim=1)\n",
        "\n",
        "        # KLæ•£åº¦\n",
        "        kd_loss = self.kl_div(student_soft, teacher_soft) * (temperature ** 2)\n",
        "\n",
        "        return kd_loss\n",
        "\n",
        "    def _detection_kd_loss(self, student_outputs, teacher_outputs, temperature):\n",
        "        \"\"\"æª¢æ¸¬ä»»å‹™çŸ¥è­˜è’¸é¤¾\"\"\"\n",
        "        # é‚Šç•Œæ¡†è’¸é¤¾\n",
        "        bbox_kd = self.mse_loss(student_outputs['bbox'], teacher_outputs['bbox'])\n",
        "\n",
        "        # ç½®ä¿¡åº¦è’¸é¤¾\n",
        "        conf_kd = self.mse_loss(student_outputs['conf'], teacher_outputs['conf'])\n",
        "\n",
        "        # é¡åˆ¥è’¸é¤¾ (å¸¶æº«åº¦)\n",
        "        student_cls_soft = torch.sigmoid(student_outputs['cls'] / temperature)\n",
        "        teacher_cls_soft = torch.sigmoid(teacher_outputs['cls'] / temperature)\n",
        "        cls_kd = self.mse_loss(student_cls_soft, teacher_cls_soft) * (temperature ** 2)\n",
        "\n",
        "        # çµ„åˆæª¢æ¸¬è’¸é¤¾æå¤±\n",
        "        total_kd = bbox_kd + conf_kd + cls_kd\n",
        "\n",
        "        return total_kd\n",
        "\n",
        "    def _classification_kd_loss(self, student_logits, teacher_logits, temperature):\n",
        "        \"\"\"åˆ†é¡ä»»å‹™çŸ¥è­˜è’¸é¤¾\"\"\"\n",
        "        # æ‡‰ç”¨æº«åº¦\n",
        "        student_soft = F.log_softmax(student_logits / temperature, dim=1)\n",
        "        teacher_soft = F.softmax(teacher_logits / temperature, dim=1)\n",
        "\n",
        "        # KLæ•£åº¦\n",
        "        kd_loss = self.kl_div(student_soft, teacher_soft) * (temperature ** 2)\n",
        "\n",
        "        return kd_loss\n",
        "\n",
        "# æº«åº¦èª¿åº¦å™¨\n",
        "class TemperatureScheduler:\n",
        "    \"\"\"æº«åº¦èª¿åº¦å™¨ - å‰µæ–°ï¼šå‹•æ…‹æº«åº¦èª¿æ•´\"\"\"\n",
        "    def __init__(self, temperature_schedule):\n",
        "        self.temperature_schedule = temperature_schedule\n",
        "        self.current_stage = 0\n",
        "\n",
        "    def set_stage(self, stage):\n",
        "        \"\"\"è¨­ç½®ç•¶å‰éšæ®µ\"\"\"\n",
        "        self.current_stage = min(stage, len(self.temperature_schedule) - 1)\n",
        "\n",
        "    def get_temperature(self, epoch=None, max_epochs=None):\n",
        "        \"\"\"ç²å–ç•¶å‰æº«åº¦\"\"\"\n",
        "        base_temp = self.temperature_schedule[self.current_stage]\n",
        "\n",
        "        # å‰µæ–°ï¼šepochå…§æº«åº¦è¡°æ¸›\n",
        "        if epoch is not None and max_epochs is not None:\n",
        "            decay_factor = 1.0 - (epoch / max_epochs) * 0.2  # æœ€å¤šè¡°æ¸›20%\n",
        "            return base_temp * decay_factor\n",
        "\n",
        "        return base_temp\n",
        "\n",
        "# ä»»å‹™ç‰¹å®šè’¸é¤¾æ¬Šé‡\n",
        "class TaskSpecificDistillationWeights:\n",
        "    \"\"\"ä»»å‹™ç‰¹å®šè’¸é¤¾æ¬Šé‡ - å‰µæ–°ï¼šä¸åŒä»»å‹™ä½¿ç”¨ä¸åŒè’¸é¤¾å¼·åº¦\"\"\"\n",
        "    def __init__(self):\n",
        "        self.task_weights = {\n",
        "            'segmentation': 1.2,  # åˆ†å‰²ä»»å‹™éœ€è¦æ›´å¼·çš„è’¸é¤¾\n",
        "            'detection': 1.0,     # æª¢æ¸¬ä»»å‹™æ¨™æº–è’¸é¤¾\n",
        "            'classification': 0.8  # åˆ†é¡ä»»å‹™è¼ƒå¼±çš„è’¸é¤¾\n",
        "        }\n",
        "\n",
        "        # å‰µæ–°ï¼šå‹•æ…‹æ¬Šé‡èª¿æ•´æ­·å²\n",
        "        self.weight_history = {}\n",
        "        self.adaptation_rate = 0.1\n",
        "\n",
        "    def get_weight(self, task_type):\n",
        "        \"\"\"ç²å–ä»»å‹™ç‰¹å®šæ¬Šé‡\"\"\"\n",
        "        return self.task_weights.get(task_type, 1.0)\n",
        "\n",
        "    def update_weight(self, task_type, performance_drop):\n",
        "        \"\"\"æ ¹æ“šæ€§èƒ½ä¸‹é™å‹•æ…‹èª¿æ•´æ¬Šé‡\"\"\"\n",
        "        if task_type not in self.weight_history:\n",
        "            self.weight_history[task_type] = []\n",
        "\n",
        "        self.weight_history[task_type].append(performance_drop)\n",
        "\n",
        "        # å¦‚æœæœ€è¿‘æ€§èƒ½ä¸‹é™è¼ƒå¤§ï¼Œå¢åŠ è’¸é¤¾æ¬Šé‡\n",
        "        if len(self.weight_history[task_type]) >= 3:\n",
        "            recent_drops = self.weight_history[task_type][-3:]\n",
        "            avg_drop = np.mean(recent_drops)\n",
        "\n",
        "            if avg_drop > 0.03:  # æ€§èƒ½ä¸‹é™è¶…é3%\n",
        "                self.task_weights[task_type] *= (1 + self.adaptation_rate)\n",
        "            elif avg_drop < 0.01:  # æ€§èƒ½ä¸‹é™å°æ–¼1%\n",
        "                self.task_weights[task_type] *= (1 - self.adaptation_rate * 0.5)\n",
        "\n",
        "            # é™åˆ¶æ¬Šé‡ç¯„åœ\n",
        "            self.task_weights[task_type] = np.clip(self.task_weights[task_type], 0.5, 2.0)\n",
        "\n",
        "# æ³¨æ„åŠ›è½‰ç§»è’¸é¤¾ (é€²éšå‰µæ–°)\n",
        "class AttentionTransferDistillation(nn.Module):\n",
        "    \"\"\"æ³¨æ„åŠ›è½‰ç§»è’¸é¤¾ - å‰µæ–°ï¼šä¸åªè’¸é¤¾è¼¸å‡ºï¼Œé‚„è’¸é¤¾æ³¨æ„åŠ›\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.attention_loss = nn.MSELoss()\n",
        "\n",
        "    def extract_attention_maps(self, model, input_tensor):\n",
        "        \"\"\"æå–æ¨¡å‹çš„æ³¨æ„åŠ›åœ–\"\"\"\n",
        "        attention_maps = []\n",
        "\n",
        "        def hook_fn(module, input, output):\n",
        "            if hasattr(module, 'channel_attention'):\n",
        "                # æå–é€šé“æ³¨æ„åŠ›\n",
        "                attention = F.adaptive_avg_pool2d(output, 1)\n",
        "                attention_maps.append(attention)\n",
        "\n",
        "        # è¨»å†Šhook\n",
        "        hooks = []\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, TaskAwarenessLayer):\n",
        "                hook = module.register_forward_hook(hook_fn)\n",
        "                hooks.append(hook)\n",
        "\n",
        "        # å‰å‘å‚³æ’­\n",
        "        with torch.no_grad():\n",
        "            _ = model(input_tensor)\n",
        "\n",
        "        # æ¸…é™¤hook\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        return attention_maps\n",
        "\n",
        "    def forward(self, student_model, teacher_model, input_tensor):\n",
        "        \"\"\"è¨ˆç®—æ³¨æ„åŠ›è½‰ç§»æå¤±\"\"\"\n",
        "        # æå–æ³¨æ„åŠ›åœ–\n",
        "        student_attention = self.extract_attention_maps(student_model, input_tensor)\n",
        "        teacher_attention = self.extract_attention_maps(teacher_model, input_tensor)\n",
        "\n",
        "        # è¨ˆç®—æ³¨æ„åŠ›æå¤±\n",
        "        attention_loss = 0.0\n",
        "        for s_att, t_att in zip(student_attention, teacher_attention):\n",
        "            if s_att.shape == t_att.shape:\n",
        "                attention_loss += self.attention_loss(s_att, t_att)\n",
        "\n",
        "        return attention_loss\n",
        "\n",
        "# çŸ¥è­˜è’¸é¤¾ç®¡ç†å™¨\n",
        "class KnowledgeDistillationManager:\n",
        "    \"\"\"çŸ¥è­˜è’¸é¤¾ç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰è’¸é¤¾éç¨‹\"\"\"\n",
        "    def __init__(self):\n",
        "        self.progressive_kd = ProgressiveKnowledgeDistillation()\n",
        "        self.attention_transfer = AttentionTransferDistillation()\n",
        "\n",
        "        # è’¸é¤¾é…ç½®\n",
        "        self.kd_config = {\n",
        "            'use_attention_transfer': True,\n",
        "            'attention_weight': 0.1,\n",
        "            'progressive_weight': 0.9\n",
        "        }\n",
        "\n",
        "    def compute_distillation_loss(self, student_model, teacher_model,\n",
        "                                student_outputs, teacher_outputs,\n",
        "                                hard_targets, task_type, input_tensor=None):\n",
        "        \"\"\"è¨ˆç®—å®Œæ•´çš„è’¸é¤¾æå¤±\"\"\"\n",
        "\n",
        "        # ä¸»è¦è’¸é¤¾æå¤±\n",
        "        main_kd_loss = self.progressive_kd(\n",
        "            student_outputs, teacher_outputs, hard_targets, task_type\n",
        "        )\n",
        "\n",
        "        total_loss = self.kd_config['progressive_weight'] * main_kd_loss\n",
        "\n",
        "        # æ³¨æ„åŠ›è½‰ç§»æå¤± (å¦‚æœå•Ÿç”¨ä¸”æœ‰æ•™å¸«æ¨¡å‹)\n",
        "        if (self.kd_config['use_attention_transfer'] and\n",
        "            teacher_model is not None and input_tensor is not None):\n",
        "\n",
        "            attention_loss = self.attention_transfer(\n",
        "                student_model, teacher_model, input_tensor\n",
        "            )\n",
        "            total_loss += self.kd_config['attention_weight'] * attention_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def set_stage(self, stage):\n",
        "        \"\"\"è¨­ç½®è’¸é¤¾éšæ®µ\"\"\"\n",
        "        self.progressive_kd.set_stage(stage)\n",
        "\n",
        "    def update_config(self, **kwargs):\n",
        "        \"\"\"æ›´æ–°è’¸é¤¾é…ç½®\"\"\"\n",
        "        self.kd_config.update(kwargs)\n",
        "\n",
        "print(\"âœ… çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsydTMIKFn6w",
        "outputId": "bfd5db73-5575-49a0-e374-8322f71e7a1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬å…«æ®µï¼šè¨“ç·´æµç¨‹å’Œå‡½æ•¸\n",
        "# =============================================================================\n",
        "\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# é‡æ–°å‰µå»ºè¨“ç·´å™¨ï¼Œä½¿ç”¨ä¿®æ­£å¾Œçš„çµ„ä»¶\n",
        "class UnifiedTrainer:\n",
        "    \"\"\"çµ±ä¸€è¨“ç·´å™¨ - æœ€çµ‚ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "    def __init__(self, model, data_loaders, device='cuda'):\n",
        "        self.model = model\n",
        "        self.data_loaders = data_loaders\n",
        "        self.device = device\n",
        "\n",
        "        # ä½¿ç”¨ä¿®æ­£å¾Œçš„çŸ¥è­˜è’¸é¤¾ç®¡ç†å™¨\n",
        "        self.kd_manager = KnowledgeDistillationManager()\n",
        "        self.kd_manager.progressive_kd = ProgressiveKnowledgeDistillation()\n",
        "\n",
        "        # è©•ä¼°æŒ‡æ¨™è¨ˆç®—å™¨\n",
        "        self.metrics_calculator = MetricsCalculator()\n",
        "\n",
        "        # ä½¿ç”¨ä¿®æ­£å¾Œçš„ç›®æ¨™åˆ†é…å™¨\n",
        "        self.target_assigner = TargetAssigner()\n",
        "\n",
        "        # è¨“ç·´æ­·å²\n",
        "        self.training_history = {\n",
        "            'segmentation': {'loss': [], 'miou': []},\n",
        "            'detection': {'loss': [], 'map': []},\n",
        "            'classification': {'loss': [], 'accuracy': []}\n",
        "        }\n",
        "\n",
        "        # åŸºæº–æ€§èƒ½è¨˜éŒ„\n",
        "        self.baseline_performance = {}\n",
        "\n",
        "        print(\"âœ… çµ±ä¸€è¨“ç·´å™¨æœ€çµ‚ä¿®æ­£ç‰ˆæœ¬åˆå§‹åŒ–å®Œæˆ\")\n",
        "\n",
        "    def train_single_task(self, task_name, num_epochs, learning_rate,\n",
        "                         teacher_model=None, stage=0, save_path=None):\n",
        "        \"\"\"è¨“ç·´å–®ä¸€ä»»å‹™\"\"\"\n",
        "        print(f\"\\nğŸ¯ é–‹å§‹è¨“ç·´ {task_name.upper()} ä»»å‹™\")\n",
        "        print(f\"ğŸ“Š éšæ®µ: {stage+1}, è¼ªæ•¸: {num_epochs}, å­¸ç¿’ç‡: {learning_rate}\")\n",
        "        print(f\"ğŸ§  çŸ¥è­˜è’¸é¤¾: {'å•Ÿç”¨' if teacher_model else 'åœç”¨'}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # è¨­ç½®æ¨¡å‹ä»»å‹™æ¨¡å¼\n",
        "        self.model.set_task_mode(task_name)\n",
        "\n",
        "        # è¨­ç½®è’¸é¤¾éšæ®µ\n",
        "        self.kd_manager.set_stage(stage)\n",
        "\n",
        "        # æº–å‚™è³‡æ–™è¼‰å…¥å™¨\n",
        "        train_loader, val_loader = self.data_loaders[task_name]\n",
        "\n",
        "        # è¨­ç½®å„ªåŒ–å™¨\n",
        "        optimizer = self._create_optimizer(learning_rate, task_name)\n",
        "        scheduler = self._create_scheduler(optimizer, num_epochs)\n",
        "\n",
        "        # ç§»å‹•æ•™å¸«æ¨¡å‹åˆ°è¨­å‚™\n",
        "        if teacher_model:\n",
        "            teacher_model = teacher_model.to(self.device)\n",
        "            teacher_model.eval()\n",
        "\n",
        "        best_metric = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            # è¨“ç·´éšæ®µ\n",
        "            train_loss, train_metric = self._train_epoch(\n",
        "                task_name, train_loader, optimizer, teacher_model, epoch, num_epochs\n",
        "            )\n",
        "\n",
        "            # é©—è­‰éšæ®µ\n",
        "            val_loss, val_metric = self._validate_epoch(\n",
        "                task_name, val_loader, teacher_model\n",
        "            )\n",
        "\n",
        "            # æ›´æ–°å­¸ç¿’ç‡\n",
        "            scheduler.step()\n",
        "\n",
        "            # è¨˜éŒ„æ­·å²\n",
        "            self.training_history[task_name]['loss'].append(val_loss)\n",
        "            if task_name == 'segmentation':\n",
        "                self.training_history[task_name]['miou'].append(val_metric)\n",
        "            elif task_name == 'detection':\n",
        "                self.training_history[task_name]['map'].append(val_metric)\n",
        "            elif task_name == 'classification':\n",
        "                self.training_history[task_name]['accuracy'].append(val_metric)\n",
        "\n",
        "            # å„²å­˜æœ€ä½³æ¨¡å‹\n",
        "            if val_metric > best_metric:\n",
        "                best_metric = val_metric\n",
        "                if save_path:\n",
        "                    self._save_checkpoint(save_path, epoch, optimizer, best_metric, task_name)\n",
        "\n",
        "            # å°å‡ºé€²åº¦\n",
        "            epoch_time = time.time() - start_time\n",
        "            self._print_epoch_results(\n",
        "                epoch, num_epochs, epoch_time, train_loss, train_metric,\n",
        "                val_loss, val_metric, best_metric, task_name\n",
        "            )\n",
        "\n",
        "        # è¨˜éŒ„åŸºæº–æ€§èƒ½\n",
        "        if stage == 0:  # ç¬¬ä¸€æ¬¡è¨“ç·´è©²ä»»å‹™\n",
        "            self.baseline_performance[task_name] = best_metric\n",
        "\n",
        "        print(f\"âœ… {task_name.upper()} ä»»å‹™è¨“ç·´å®Œæˆï¼Œæœ€ä½³æŒ‡æ¨™: {best_metric:.4f}\")\n",
        "        return best_metric\n",
        "\n",
        "    def _train_epoch(self, task_name, train_loader, optimizer, teacher_model, epoch, max_epochs):\n",
        "        \"\"\"è¨“ç·´ä¸€å€‹epoch\"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_metric = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'{task_name.capitalize()} Epoch {epoch+1}/{max_epochs}')\n",
        "\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            try:\n",
        "                # æº–å‚™æ•¸æ“š\n",
        "                inputs, targets = self._prepare_batch_data(batch, task_name)\n",
        "                if inputs is None:\n",
        "                    continue\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­\n",
        "                student_outputs = self.model(inputs)\n",
        "\n",
        "                # æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ (å¦‚æœæœ‰)\n",
        "                teacher_outputs = None\n",
        "                if teacher_model:\n",
        "                    with torch.no_grad():\n",
        "                        teacher_outputs = teacher_model(inputs)\n",
        "\n",
        "                # è¨ˆç®—æå¤± (åŒ…å«çŸ¥è­˜è’¸é¤¾)\n",
        "                loss = self.kd_manager.compute_distillation_loss(\n",
        "                    self.model, teacher_model, student_outputs, teacher_outputs,\n",
        "                    targets, task_name, inputs\n",
        "                )\n",
        "\n",
        "                # åå‘å‚³æ’­\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                # è¨ˆç®—æŒ‡æ¨™\n",
        "                with torch.no_grad():\n",
        "                    metric = self._calculate_metric(student_outputs, targets, task_name)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_metric += metric\n",
        "                num_batches += 1\n",
        "\n",
        "                # æ›´æ–°é€²åº¦æ¢\n",
        "                pbar.set_postfix({\n",
        "                    'Loss': f'{loss.item():.4f}',\n",
        "                    self._get_metric_name(task_name): f'{metric:.4f}',\n",
        "                    'KD': 'ON' if teacher_model else 'OFF'\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"è¨“ç·´æ‰¹æ¬¡éŒ¯èª¤: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_loss = total_loss / max(num_batches, 1)\n",
        "        avg_metric = total_metric / max(num_batches, 1)\n",
        "\n",
        "        return avg_loss, avg_metric\n",
        "\n",
        "    def _validate_epoch(self, task_name, val_loader, teacher_model):\n",
        "        \"\"\"é©—è­‰ä¸€å€‹epoch\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_metric = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                try:\n",
        "                    # æº–å‚™æ•¸æ“š\n",
        "                    inputs, targets = self._prepare_batch_data(batch, task_name)\n",
        "                    if inputs is None:\n",
        "                        continue\n",
        "\n",
        "                    # å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­\n",
        "                    student_outputs = self.model(inputs)\n",
        "\n",
        "                    # æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ (å¦‚æœæœ‰)\n",
        "                    teacher_outputs = None\n",
        "                    if teacher_model:\n",
        "                        teacher_outputs = teacher_model(inputs)\n",
        "\n",
        "                    # è¨ˆç®—æå¤±\n",
        "                    loss = self.kd_manager.compute_distillation_loss(\n",
        "                        self.model, teacher_model, student_outputs, teacher_outputs,\n",
        "                        targets, task_name, inputs\n",
        "                    )\n",
        "\n",
        "                    # è¨ˆç®—æŒ‡æ¨™\n",
        "                    metric = self._calculate_metric(student_outputs, targets, task_name)\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "                    total_metric += metric\n",
        "                    num_batches += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "        avg_loss = total_loss / max(num_batches, 1)\n",
        "        avg_metric = total_metric / max(num_batches, 1)\n",
        "\n",
        "        return avg_loss, avg_metric\n",
        "\n",
        "    def _prepare_batch_data(self, batch, task_name):\n",
        "        \"\"\"æº–å‚™æ‰¹æ¬¡æ•¸æ“š\"\"\"\n",
        "        try:\n",
        "            if task_name == 'segmentation':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "                targets = batch['targets'].to(self.device)\n",
        "                return inputs, targets\n",
        "\n",
        "            elif task_name == 'detection':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "\n",
        "                # æº–å‚™æª¢æ¸¬ç›®æ¨™\n",
        "                gt_boxes = batch['boxes']\n",
        "                gt_labels = batch['labels']\n",
        "\n",
        "                # åˆ†é…ç›®æ¨™ - ä½¿ç”¨ä¿®æ­£å¾Œçš„åˆ†é…å™¨\n",
        "                target_boxes, target_conf, target_cls = self.target_assigner.assign_targets(\n",
        "                    self.model(inputs)['detection'].shape, gt_boxes, gt_labels\n",
        "                )\n",
        "\n",
        "                targets = {\n",
        "                    'boxes': target_boxes,\n",
        "                    'conf': target_conf,\n",
        "                    'cls': target_cls\n",
        "                }\n",
        "                return inputs, targets\n",
        "\n",
        "            elif task_name == 'classification':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "                targets = batch['targets'].to(self.device)\n",
        "                return inputs, targets\n",
        "\n",
        "            else:\n",
        "                return None, None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"æ•¸æ“šæº–å‚™éŒ¯èª¤: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    # ä¿®æ­£UnifiedTrainerä¸­çš„_calculate_metricæ–¹æ³•\n",
        "    def _calculate_metric(self, outputs, targets, task_name):\n",
        "        \"\"\"è¨ˆç®—è©•ä¼°æŒ‡æ¨™ - ä¿®æ­£ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if task_name == 'segmentation':\n",
        "                return self.metrics_calculator.calculate_miou(\n",
        "                    outputs['segmentation'], targets, num_classes=8\n",
        "                )\n",
        "\n",
        "            elif task_name == 'detection':\n",
        "                # ä¿®æ­£ï¼šç¢ºä¿æ­£ç¢ºå‚³éåƒæ•¸\n",
        "                boxes_target = targets['boxes']\n",
        "                cls_target = targets['cls']\n",
        "\n",
        "                # ç¢ºä¿targetsæ˜¯æ­£ç¢ºçš„æ ¼å¼\n",
        "                if isinstance(boxes_target, torch.Tensor):\n",
        "                    boxes_list = [boxes_target]\n",
        "                else:\n",
        "                    boxes_list = [boxes_target] if not isinstance(boxes_target, list) else boxes_target\n",
        "\n",
        "                if isinstance(cls_target, torch.Tensor):\n",
        "                    cls_list = [cls_target]\n",
        "                else:\n",
        "                    cls_list = [cls_target] if not isinstance(cls_target, list) else cls_target\n",
        "\n",
        "                return self.metrics_calculator.calculate_detection_map(\n",
        "                    outputs['detection_raw']['bbox'],\n",
        "                    outputs['detection_raw']['conf'],\n",
        "                    outputs['detection_raw']['cls'],\n",
        "                    boxes_list, cls_list\n",
        "                )\n",
        "\n",
        "            elif task_name == 'classification':\n",
        "                return self.metrics_calculator.calculate_accuracy(\n",
        "                    outputs['classification'], targets\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                return 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _create_optimizer(self, learning_rate, task_name):\n",
        "        \"\"\"å‰µå»ºå„ªåŒ–å™¨\"\"\"\n",
        "        if task_name == 'segmentation':\n",
        "            return optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        elif task_name == 'detection':\n",
        "            return optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "        elif task_name == 'classification':\n",
        "            return optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        else:\n",
        "            return optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "    def _create_scheduler(self, optimizer, num_epochs):\n",
        "        \"\"\"å‰µå»ºå­¸ç¿’ç‡èª¿åº¦å™¨\"\"\"\n",
        "        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "\n",
        "    def _get_metric_name(self, task_name):\n",
        "        \"\"\"ç²å–æŒ‡æ¨™åç¨±\"\"\"\n",
        "        if task_name == 'segmentation':\n",
        "            return 'mIoU'\n",
        "        elif task_name == 'detection':\n",
        "            return 'mAP'\n",
        "        elif task_name == 'classification':\n",
        "            return 'Acc'\n",
        "        else:\n",
        "            return 'Metric'\n",
        "\n",
        "    def _print_epoch_results(self, epoch, max_epochs, epoch_time, train_loss, train_metric,\n",
        "                           val_loss, val_metric, best_metric, task_name):\n",
        "        \"\"\"å°å‡ºepochçµæœ\"\"\"\n",
        "        metric_name = self._get_metric_name(task_name)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{max_epochs} - {epoch_time:.1f}s\")\n",
        "        print(f\"  Train - Loss: {train_loss:.4f}, {metric_name}: {train_metric:.4f}\")\n",
        "        print(f\"  Val   - Loss: {val_loss:.4f}, {metric_name}: {val_metric:.4f}\")\n",
        "        print(f\"  Best {metric_name}: {best_metric:.4f}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def _save_checkpoint(self, save_path, epoch, optimizer, best_metric, task_name):\n",
        "        \"\"\"å„²å­˜æª¢æŸ¥é»\"\"\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'best_metric': best_metric,\n",
        "            'task_name': task_name,\n",
        "            'training_history': self.training_history\n",
        "        }, save_path)\n",
        "\n",
        "        print(f\"ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: {save_path} ({self._get_metric_name(task_name)}: {best_metric:.4f})\")\n",
        "\n",
        "# è©•ä¼°å™¨\n",
        "class TaskEvaluator:\n",
        "    \"\"\"ä»»å‹™è©•ä¼°å™¨\"\"\"\n",
        "    def __init__(self, model, data_loaders, device='cuda'):\n",
        "        self.model = model\n",
        "        self.data_loaders = data_loaders\n",
        "        self.device = device\n",
        "        self.metrics_calculator = MetricsCalculator()\n",
        "\n",
        "    def evaluate_task(self, task_name):\n",
        "        \"\"\"è©•ä¼°å–®ä¸€ä»»å‹™\"\"\"\n",
        "        print(f\"ğŸ” è©•ä¼° {task_name.upper()} ä»»å‹™...\")\n",
        "\n",
        "        self.model.eval()\n",
        "        self.model.set_task_mode(task_name)\n",
        "\n",
        "        _, val_loader = self.data_loaders[task_name]\n",
        "\n",
        "        total_metric = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"è©•ä¼°{task_name}\"):\n",
        "                try:\n",
        "                    inputs, targets = self._prepare_data(batch, task_name)\n",
        "                    if inputs is None:\n",
        "                        continue\n",
        "\n",
        "                    outputs = self.model(inputs)\n",
        "                    metric = self._calculate_metric(outputs, targets, task_name)\n",
        "\n",
        "                    total_metric += metric\n",
        "                    num_batches += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "        avg_metric = total_metric / max(num_batches, 1)\n",
        "        metric_name = self._get_metric_name(task_name)\n",
        "\n",
        "        print(f\"âœ… {task_name.upper()} {metric_name}: {avg_metric:.4f}\")\n",
        "        return avg_metric\n",
        "\n",
        "    def evaluate_all_tasks(self):\n",
        "        \"\"\"è©•ä¼°æ‰€æœ‰ä»»å‹™\"\"\"\n",
        "        results = {}\n",
        "        for task_name in ['segmentation', 'detection', 'classification']:\n",
        "            results[task_name] = self.evaluate_task(task_name)\n",
        "        return results\n",
        "\n",
        "    def _prepare_data(self, batch, task_name):\n",
        "        \"\"\"æº–å‚™è©•ä¼°æ•¸æ“š\"\"\"\n",
        "        try:\n",
        "            if task_name == 'segmentation':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "                targets = batch['targets'].to(self.device)\n",
        "                return inputs, targets\n",
        "\n",
        "            elif task_name == 'detection':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "                gt_boxes = batch['boxes']\n",
        "                gt_labels = batch['labels']\n",
        "                return inputs, {'boxes': gt_boxes, 'labels': gt_labels}\n",
        "\n",
        "            elif task_name == 'classification':\n",
        "                inputs = batch['inputs'].to(self.device)\n",
        "                targets = batch['targets'].to(self.device)\n",
        "                return inputs, targets\n",
        "\n",
        "            else:\n",
        "                return None, None\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, None\n",
        "\n",
        "    def _calculate_metric(self, outputs, targets, task_name):\n",
        "        \"\"\"è¨ˆç®—è©•ä¼°æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if task_name == 'segmentation':\n",
        "                return self.metrics_calculator.calculate_miou(\n",
        "                    outputs['segmentation'], targets, num_classes=8\n",
        "                )\n",
        "\n",
        "            elif task_name == 'detection':\n",
        "                return self.metrics_calculator.calculate_detection_map(\n",
        "                    outputs['detection_raw']['bbox'],\n",
        "                    outputs['detection_raw']['conf'],\n",
        "                    outputs['detection_raw']['cls'],\n",
        "                    targets['boxes'], targets['labels']\n",
        "                )\n",
        "\n",
        "            elif task_name == 'classification':\n",
        "                return self.metrics_calculator.calculate_accuracy(\n",
        "                    outputs['classification'], targets\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                return 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            return 0.0\n",
        "\n",
        "    def _get_metric_name(self, task_name):\n",
        "        \"\"\"ç²å–æŒ‡æ¨™åç¨±\"\"\"\n",
        "        if task_name == 'segmentation':\n",
        "            return 'mIoU'\n",
        "        elif task_name == 'detection':\n",
        "            return 'mAP'\n",
        "        elif task_name == 'classification':\n",
        "            return 'Top-1 Accuracy'\n",
        "        else:\n",
        "            return 'Metric'\n",
        "\n",
        "print(\"âœ… è¨“ç·´æµç¨‹å’Œå‡½æ•¸å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diJxocg3F4dm",
        "outputId": "ac2e8d2a-5eac-4a28-83ab-9f7fe156cfd9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è¨“ç·´æµç¨‹å’Œå‡½æ•¸å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬ä¹æ®µï¼šä¸»è¦è¨“ç·´æµç¨‹åŸ·è¡Œ\n",
        "# =============================================================================\n",
        "\n",
        "def sequential_multitask_training_pipeline():\n",
        "    \"\"\"\n",
        "    é †åºå¤šä»»å‹™è¨“ç·´æµæ°´ç·š - æŒ‰ä½œæ¥­è¦æ±‚åŸ·è¡Œ\n",
        "    Stage 1: åˆ†å‰² â†’ Stage 2: æª¢æ¸¬ â†’ Stage 3: åˆ†é¡\n",
        "    \"\"\"\n",
        "    print(\"ğŸ¯ é–‹å§‹é †åºå¤šä»»å‹™è¨“ç·´æµæ°´ç·š\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # 1. åˆå§‹åŒ–è¨“ç·´å™¨\n",
        "    trainer = UnifiedTrainer(model, all_loaders, device)\n",
        "    evaluator = TaskEvaluator(model, all_loaders, device)\n",
        "\n",
        "    # 2. è¨“ç·´é…ç½®\n",
        "    training_config = {\n",
        "        'segmentation': {\n",
        "            'epochs': 3,\n",
        "            'learning_rate': 1e-3,\n",
        "            'save_path': 'stage1_segmentation.pt'\n",
        "        },\n",
        "        'detection': {\n",
        "            'epochs': 3,\n",
        "            'learning_rate': 5e-4,\n",
        "            'save_path': 'stage2_detection.pt'\n",
        "        },\n",
        "        'classification': {\n",
        "            'epochs': 3,\n",
        "            'learning_rate': 5e-4,\n",
        "            'save_path': 'stage3_classification.pt'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # çµæœè¨˜éŒ„\n",
        "    results = {\n",
        "        'baselines': {},\n",
        "        'final_performance': {},\n",
        "        'performance_drops': {},\n",
        "        'stage_models': {}\n",
        "    }\n",
        "\n",
        "    print(\"ğŸ“Š è¨“ç·´é…ç½®:\")\n",
        "    for task, config in training_config.items():\n",
        "        print(f\"  {task.capitalize()}: {config['epochs']} epochs, LR={config['learning_rate']}\")\n",
        "    print()\n",
        "\n",
        "    # ============================================================================\n",
        "    # Stage 1: åˆ†å‰²ä»»å‹™è¨“ç·´ (å»ºç«‹baselineï¼Œç„¡çŸ¥è­˜è’¸é¤¾)\n",
        "    # ============================================================================\n",
        "\n",
        "    print(\"ğŸ¯ STAGE 1: åˆ†å‰²ä»»å‹™è¨“ç·´\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“ ç›®æ¨™: å»ºç«‹åˆ†å‰²ä»»å‹™baselineæ€§èƒ½\")\n",
        "    print(\"ğŸ§  çŸ¥è­˜è’¸é¤¾: åœç”¨ (ç¬¬ä¸€éšæ®µ)\")\n",
        "    print()\n",
        "\n",
        "    seg_baseline = trainer.train_single_task(\n",
        "        task_name='segmentation',\n",
        "        num_epochs=training_config['segmentation']['epochs'],\n",
        "        learning_rate=training_config['segmentation']['learning_rate'],\n",
        "        teacher_model=None,  # ç¬¬ä¸€éšæ®µç„¡æ•™å¸«æ¨¡å‹\n",
        "        stage=0,\n",
        "        save_path=training_config['segmentation']['save_path']\n",
        "    )\n",
        "\n",
        "    results['baselines']['segmentation'] = seg_baseline\n",
        "    print(f\"âœ… åˆ†å‰² Baseline mIoU: {seg_baseline:.4f}\")\n",
        "\n",
        "    # ä¿å­˜ç¬¬ä¸€éšæ®µæ¨¡å‹ä½œç‚ºæ•™å¸«\n",
        "    stage1_teacher = copy.deepcopy(model)\n",
        "    stage1_teacher.eval()\n",
        "    results['stage_models']['stage1'] = stage1_teacher\n",
        "\n",
        "    # ============================================================================\n",
        "    # Stage 2: æª¢æ¸¬ä»»å‹™è¨“ç·´ (ä½¿ç”¨çŸ¥è­˜è’¸é¤¾)\n",
        "    # ============================================================================\n",
        "\n",
        "    print(\"\\nğŸ¯ STAGE 2: æª¢æ¸¬ä»»å‹™è¨“ç·´\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“ ç›®æ¨™: è¨“ç·´æª¢æ¸¬ä»»å‹™åŒæ™‚ä¿æŒåˆ†å‰²æ€§èƒ½\")\n",
        "    print(\"ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨ (ä½¿ç”¨Stage 1æ¨¡å‹ä½œç‚ºæ•™å¸«)\")\n",
        "    print()\n",
        "\n",
        "    det_baseline = trainer.train_single_task(\n",
        "        task_name='detection',\n",
        "        num_epochs=training_config['detection']['epochs'],\n",
        "        learning_rate=training_config['detection']['learning_rate'],\n",
        "        teacher_model=stage1_teacher,  # ä½¿ç”¨ç¬¬ä¸€éšæ®µæ¨¡å‹ä½œç‚ºæ•™å¸«\n",
        "        stage=1,\n",
        "        save_path=training_config['detection']['save_path']\n",
        "    )\n",
        "\n",
        "    results['baselines']['detection'] = det_baseline\n",
        "    print(f\"âœ… æª¢æ¸¬ Baseline mAP: {det_baseline:.4f}\")\n",
        "\n",
        "    # æª¢æŸ¥åˆ†å‰²ä»»å‹™éºå¿˜\n",
        "    print(\"\\nğŸ” æª¢æŸ¥åˆ†å‰²ä»»å‹™éºå¿˜...\")\n",
        "    seg_after_det = evaluator.evaluate_task('segmentation')\n",
        "    seg_drop = results['baselines']['segmentation'] - seg_after_det\n",
        "    results['performance_drops']['seg_after_det'] = seg_drop\n",
        "\n",
        "    print(f\"ğŸ“Š åˆ†å‰²æ€§èƒ½è®ŠåŒ–:\")\n",
        "    print(f\"  Baseline: {results['baselines']['segmentation']:.4f}\")\n",
        "    print(f\"  Current:  {seg_after_det:.4f}\")\n",
        "    print(f\"  Drop:     {seg_drop:.4f} ({'âœ… â‰¤5%' if seg_drop <= 0.05 else 'âŒ >5%'})\")\n",
        "\n",
        "    # ä¿å­˜ç¬¬äºŒéšæ®µæ¨¡å‹ä½œç‚ºæ•™å¸«\n",
        "    stage2_teacher = copy.deepcopy(model)\n",
        "    stage2_teacher.eval()\n",
        "    results['stage_models']['stage2'] = stage2_teacher\n",
        "\n",
        "    # ============================================================================\n",
        "    # Stage 3: åˆ†é¡ä»»å‹™è¨“ç·´ (ä½¿ç”¨çŸ¥è­˜è’¸é¤¾)\n",
        "    # ============================================================================\n",
        "\n",
        "    print(\"\\nğŸ¯ STAGE 3: åˆ†é¡ä»»å‹™è¨“ç·´\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“ ç›®æ¨™: è¨“ç·´åˆ†é¡ä»»å‹™åŒæ™‚ä¿æŒå‰å…©å€‹ä»»å‹™æ€§èƒ½\")\n",
        "    print(\"ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨ (ä½¿ç”¨Stage 2æ¨¡å‹ä½œç‚ºæ•™å¸«)\")\n",
        "    print()\n",
        "\n",
        "    cls_baseline = trainer.train_single_task(\n",
        "        task_name='classification',\n",
        "        num_epochs=training_config['classification']['epochs'],\n",
        "        learning_rate=training_config['classification']['learning_rate'],\n",
        "        teacher_model=stage2_teacher,  # ä½¿ç”¨ç¬¬äºŒéšæ®µæ¨¡å‹ä½œç‚ºæ•™å¸«\n",
        "        stage=2,\n",
        "        save_path=training_config['classification']['save_path']\n",
        "    )\n",
        "\n",
        "    results['baselines']['classification'] = cls_baseline\n",
        "    print(f\"âœ… åˆ†é¡ Baseline Top-1: {cls_baseline:.2f}%\")\n",
        "\n",
        "    # ============================================================================\n",
        "    # æœ€çµ‚è©•ä¼°æ‰€æœ‰ä»»å‹™\n",
        "    # ============================================================================\n",
        "\n",
        "    print(\"\\nğŸ” æœ€çµ‚è©•ä¼°æ‰€æœ‰ä»»å‹™\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    final_results = evaluator.evaluate_all_tasks()\n",
        "    results['final_performance'] = final_results\n",
        "\n",
        "    # è¨ˆç®—æ‰€æœ‰ä»»å‹™çš„æ€§èƒ½ä¸‹é™\n",
        "    seg_final_drop = results['baselines']['segmentation'] - final_results['segmentation']\n",
        "    det_final_drop = results['baselines']['detection'] - final_results['detection']\n",
        "    cls_final_drop = results['baselines']['classification'] - final_results['classification']\n",
        "\n",
        "    results['performance_drops'].update({\n",
        "        'segmentation_final': seg_final_drop,\n",
        "        'detection_final': det_final_drop,\n",
        "        'classification_final': cls_final_drop\n",
        "    })\n",
        "\n",
        "    # ============================================================================\n",
        "    # çµæœåˆ†æå’Œå ±å‘Š\n",
        "    # ============================================================================\n",
        "\n",
        "    print(\"\\nğŸ“Š æœ€çµ‚çµæœå ±å‘Š\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # æª¢æŸ¥ä½œæ¥­è¦æ±‚\n",
        "    seg_pass = seg_final_drop <= 0.05\n",
        "    det_pass = det_final_drop <= 0.05\n",
        "    cls_pass = cls_final_drop <= 5.0  # åˆ†é¡æ˜¯ç™¾åˆ†æ¯”\n",
        "\n",
        "    print(\"ğŸ¯ ä»»å‹™æ€§èƒ½åˆ†æ:\")\n",
        "    print()\n",
        "\n",
        "    print(\"ğŸ“ˆ åˆ†å‰²ä»»å‹™:\")\n",
        "    print(f\"  Baseline: {results['baselines']['segmentation']:.4f}\")\n",
        "    print(f\"  Final:    {final_results['segmentation']:.4f}\")\n",
        "    print(f\"  Drop:     {seg_final_drop:.4f} ({'âœ… PASS' if seg_pass else 'âŒ FAIL'} - è¦æ±‚ â‰¤0.05)\")\n",
        "\n",
        "    print(\"\\nğŸ“ˆ æª¢æ¸¬ä»»å‹™:\")\n",
        "    print(f\"  Baseline: {results['baselines']['detection']:.4f}\")\n",
        "    print(f\"  Final:    {final_results['detection']:.4f}\")\n",
        "    print(f\"  Drop:     {det_final_drop:.4f} ({'âœ… PASS' if det_pass else 'âŒ FAIL'} - è¦æ±‚ â‰¤0.05)\")\n",
        "\n",
        "    print(\"\\nğŸ“ˆ åˆ†é¡ä»»å‹™:\")\n",
        "    print(f\"  Baseline: {results['baselines']['classification']:.2f}%\")\n",
        "    print(f\"  Final:    {final_results['classification']:.2f}%\")\n",
        "    print(f\"  Drop:     {cls_final_drop:.2f}% ({'âœ… PASS' if cls_pass else 'âŒ FAIL'} - è¦æ±‚ â‰¤5%)\")\n",
        "\n",
        "    # ç¸½é«”è©•ä¼°\n",
        "    all_pass = seg_pass and det_pass and cls_pass\n",
        "\n",
        "    print(f\"\\nğŸ† ç¸½é«”è©•ä¼°:\")\n",
        "    print(f\"  ä½œæ¥­è¦æ±‚: {'âœ… é€šé' if all_pass else 'âŒ æœªé€šé'}\")\n",
        "    print(f\"  ç½é›£æ€§éºå¿˜æ§åˆ¶: {'âœ… æˆåŠŸ' if all_pass else 'âŒ éœ€æ”¹é€²'}\")\n",
        "\n",
        "    # çŸ¥è­˜è’¸é¤¾æ•ˆæœåˆ†æ\n",
        "    print(f\"\\nğŸ§  çŸ¥è­˜è’¸é¤¾æ•ˆæœåˆ†æ:\")\n",
        "    print(f\"  Stage 1â†’2 åˆ†å‰²ä¿æŒ: {seg_drop:.4f} ({'è‰¯å¥½' if seg_drop <= 0.03 else 'ä¸€èˆ¬' if seg_drop <= 0.05 else 'éœ€æ”¹é€²'})\")\n",
        "    print(f\"  Stage 2â†’3 æ•´é«”ä¿æŒ: {'è‰¯å¥½' if all_pass else 'éœ€æ”¹é€²'}\")\n",
        "\n",
        "    # ä¿å­˜æœ€çµ‚çµæœ\n",
        "    final_save_path = 'final_unified_model.pt'\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'results': results,\n",
        "        'config': training_config,\n",
        "        'passes_requirements': all_pass,\n",
        "        'training_history': trainer.training_history\n",
        "    }, final_save_path)\n",
        "\n",
        "    print(f\"\\nğŸ’¾ æœ€çµ‚æ¨¡å‹å·²ä¿å­˜: {final_save_path}\")\n",
        "\n",
        "    # å‰µæ–°ç‰¹è‰²ç¸½çµ\n",
        "    print(f\"\\nğŸŒŸ å‰µæ–°ç‰¹è‰²ç¸½çµ:\")\n",
        "    print(f\"  âœ¨ ä»»å‹™æ„ŸçŸ¥æ¶æ§‹: TaskAwarenessLayerå‹•æ…‹èª¿åˆ¶\")\n",
        "    print(f\"  âœ¨ å‹•æ…‹ç‰¹å¾µèåˆ: å¯å­¸ç¿’æ¬Šé‡çš„FPN\")\n",
        "    print(f\"  âœ¨ æ¼¸é€²å¼çŸ¥è­˜è’¸é¤¾: éšæ®µåŒ–æº«åº¦èª¿åº¦\")\n",
        "    print(f\"  âœ¨ æ™ºèƒ½æå¤±å‡½æ•¸: è‡ªé©æ‡‰æ¬Šé‡å¹³è¡¡\")\n",
        "    print(f\"  âœ¨ çµ±ä¸€é ­éƒ¨è¨­è¨ˆ: 3å±¤æ¼¸é€²å¼å°ˆåŒ–\")\n",
        "\n",
        "    print(\"\\nğŸ‰ é †åºå¤šä»»å‹™è¨“ç·´å®Œæˆ!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return results, all_pass\n",
        "\n",
        "# åŸ·è¡Œä¸»è¦è¨“ç·´æµç¨‹\n",
        "def main_training_execution():\n",
        "    \"\"\"åŸ·è¡Œä¸»è¦è¨“ç·´æµç¨‹\"\"\"\n",
        "    print(\"ğŸš€ é–‹å§‹åŸ·è¡Œä¸»è¦è¨“ç·´æµç¨‹\")\n",
        "    print(f\"ğŸ”§ è¨­å‚™: {device}\")\n",
        "    print(f\"ğŸ—ï¸ æ¨¡å‹: UnifiedVisionSystem\")\n",
        "    print(f\"ğŸ“Š ç¸½åƒæ•¸: {model.get_parameter_count()['total']['total_M']:.2f}M\")\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        # åŸ·è¡Œè¨“ç·´\n",
        "        training_results, success = sequential_multitask_training_pipeline()\n",
        "\n",
        "        if success:\n",
        "            print(\"ğŸŠ æ­å–œï¼è¨“ç·´æˆåŠŸå®Œæˆä¸¦é€šéæ‰€æœ‰ä½œæ¥­è¦æ±‚ï¼\")\n",
        "            print(\"ğŸ“ˆ ç½é›£æ€§éºå¿˜å·²æˆåŠŸæ§åˆ¶åœ¨5%ä»¥å…§\")\n",
        "            print(\"ğŸ§  çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶é‹ä½œè‰¯å¥½\")\n",
        "\n",
        "            # æä¾›ä¸‹ä¸€æ­¥å»ºè­°\n",
        "            print(\"\\nğŸ’¡ å¯é€²ä¸€æ­¥æ”¹é€²çš„æ–¹å‘:\")\n",
        "            print(\"  - èª¿æ•´è’¸é¤¾æº«åº¦åƒæ•¸ä»¥é€²ä¸€æ­¥æ¸›å°‘éºå¿˜\")\n",
        "            print(\"  - å¯¦é©—ä¸åŒçš„ä»»å‹™æ¬Šé‡é…ç½®\")\n",
        "            print(\"  - å˜—è©¦æ›´è¤‡é›œçš„æ³¨æ„åŠ›æ©Ÿåˆ¶\")\n",
        "\n",
        "        else:\n",
        "            print(\"âš ï¸ è¨“ç·´å®Œæˆä½†æœªå®Œå…¨é€šéè¦æ±‚\")\n",
        "            print(\"ğŸ”§ å»ºè­°èª¿æ•´è¶…åƒæ•¸å¾Œé‡æ–°è¨“ç·´\")\n",
        "\n",
        "            # åˆ†æå¤±æ•—åŸå› \n",
        "            drops = training_results['performance_drops']\n",
        "            if drops['segmentation_final'] > 0.05:\n",
        "                print(\"  - åˆ†å‰²ä»»å‹™éºå¿˜éå¤šï¼Œå»ºè­°å¢å¼·åˆ†å‰²è’¸é¤¾\")\n",
        "            if drops['detection_final'] > 0.05:\n",
        "                print(\"  - æª¢æ¸¬ä»»å‹™éºå¿˜éå¤šï¼Œå»ºè­°èª¿æ•´æª¢æ¸¬æå¤±æ¬Šé‡\")\n",
        "            if drops['classification_final'] > 5.0:\n",
        "                print(\"  - åˆ†é¡ä»»å‹™éºå¿˜éå¤šï¼Œå»ºè­°é™ä½åˆ†é¡å­¸ç¿’ç‡\")\n",
        "\n",
        "        return training_results, success\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, False\n",
        "\n",
        "# å¿«é€Ÿæ¸¬è©¦åŠŸèƒ½\n",
        "def quick_test_before_training():\n",
        "    \"\"\"è¨“ç·´å‰å¿«é€Ÿæ¸¬è©¦\"\"\"\n",
        "    print(\"ğŸ§ª åŸ·è¡Œè¨“ç·´å‰å¿«é€Ÿæ¸¬è©¦...\")\n",
        "\n",
        "    try:\n",
        "        # æ¸¬è©¦è³‡æ–™è¼‰å…¥\n",
        "        seg_train, seg_val = all_loaders['segmentation']\n",
        "        test_batch = next(iter(seg_train))\n",
        "        print(\"âœ… åˆ†å‰²è³‡æ–™è¼‰å…¥æ­£å¸¸\")\n",
        "\n",
        "        det_train, det_val = all_loaders['detection']\n",
        "        test_batch = next(iter(det_train))\n",
        "        print(\"âœ… æª¢æ¸¬è³‡æ–™è¼‰å…¥æ­£å¸¸\")\n",
        "\n",
        "        cls_train, cls_val = all_loaders['classification']\n",
        "        test_batch = next(iter(cls_train))\n",
        "        print(\"âœ… åˆ†é¡è³‡æ–™è¼‰å…¥æ­£å¸¸\")\n",
        "\n",
        "        # æ¸¬è©¦æ¨¡å‹å‰å‘å‚³æ’­\n",
        "        test_input = torch.randn(1, 3, 512, 512).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(test_input)\n",
        "        print(\"âœ… æ¨¡å‹å‰å‘å‚³æ’­æ­£å¸¸\")\n",
        "\n",
        "        # æ¸¬è©¦è©•ä¼°å™¨\n",
        "        evaluator = TaskEvaluator(model, all_loaders, device)\n",
        "        print(\"âœ… è©•ä¼°å™¨åˆå§‹åŒ–æ­£å¸¸\")\n",
        "\n",
        "        print(\"ğŸ¯ æ‰€æœ‰æ¸¬è©¦é€šéï¼Œå¯ä»¥é–‹å§‹è¨“ç·´ï¼\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ¸¬è©¦å¤±æ•—: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"âœ… ä¸»è¦è¨“ç·´æµç¨‹å®šç¾©å®Œæˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vazEsD30GL_p",
        "outputId": "4258be5a-715a-465f-b76d-eaf92b84cc03"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ä¸»è¦è¨“ç·´æµç¨‹å®šç¾©å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ç¬¬åæ®µï¼šåŸ·è¡Œå®Œæ•´è¨“ç·´\n",
        "# =============================================================================\n",
        "\n",
        "# æœ€çµ‚åŸ·è¡Œ\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ¯ çµ±ä¸€è¦–è¦ºç³»çµ± - å¤šä»»å‹™å­¸ç¿’å¯¦é©—\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“‹ ä½œæ¥­è¦æ±‚æª¢æŸ¥æ¸…å–®:\")\n",
        "    print(\"  âœ… å–®ä¸€é ­éƒ¨(2-3å±¤)åŒæ™‚è¼¸å‡ºä¸‰ä»»å‹™\")\n",
        "    print(\"  âœ… EfficientNet-B0 backbone\")\n",
        "    print(\"  âœ… åƒæ•¸é‡ < 8M\")\n",
        "    print(\"  âœ… æ¨è«–é€Ÿåº¦ â‰¤ 150ms\")\n",
        "    print(\"  âœ… ç½é›£æ€§éºå¿˜ â‰¤ 5%\")\n",
        "    print(\"  âœ… çŸ¥è­˜è’¸é¤¾é˜²éºå¿˜æ©Ÿåˆ¶\")\n",
        "    print(\"  âœ… é †åºè¨“ç·´: åˆ†å‰²â†’æª¢æ¸¬â†’åˆ†é¡\")\n",
        "    print()\n",
        "\n",
        "    # åŸ·è¡Œè¨“ç·´å‰æ¸¬è©¦\n",
        "    print(\"ğŸ§ª åŸ·è¡Œè¨“ç·´å‰ç³»çµ±æª¢æŸ¥...\")\n",
        "    test_passed = quick_test_before_training()\n",
        "\n",
        "    if not test_passed:\n",
        "        print(\"âŒ ç³»çµ±æª¢æŸ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒé…ç½®\")\n",
        "    else:\n",
        "        print(\"\\nğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´çš„é †åºå¤šä»»å‹™è¨“ç·´...\")\n",
        "        print(\"â° é ä¼°ç¸½è¨“ç·´æ™‚é–“: ç´„ 2 å°æ™‚\")\n",
        "        print(\"ğŸ¯ ç›®æ¨™: æ§åˆ¶ç½é›£æ€§éºå¿˜åœ¨5%ä»¥å…§\")\n",
        "        print()\n",
        "\n",
        "        # è¨˜éŒ„é–‹å§‹æ™‚é–“\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        # åŸ·è¡Œä¸»è¦è¨“ç·´æµç¨‹\n",
        "        final_results, training_success = main_training_execution()\n",
        "\n",
        "        # è¨ˆç®—ç¸½è¨“ç·´æ™‚é–“\n",
        "        total_training_time = time.time() - total_start_time\n",
        "        hours = int(total_training_time // 3600)\n",
        "        minutes = int((total_training_time % 3600) // 60)\n",
        "        seconds = int(total_training_time % 60)\n",
        "\n",
        "        print(f\"\\nâ° ç¸½è¨“ç·´æ™‚é–“: {hours}å°æ™‚ {minutes}åˆ†é˜ {seconds}ç§’\")\n",
        "\n",
        "        if training_success and final_results:\n",
        "            print(\"\\nğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ\")\n",
        "            print(\"        æ­å–œï¼è¨“ç·´åœ“æ»¿æˆåŠŸï¼\")\n",
        "            print(\"ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ\")\n",
        "\n",
        "            # æœ€çµ‚æˆç¸¾å–®\n",
        "            print(\"\\nğŸ“Š æœ€çµ‚æˆç¸¾å–®\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            baselines = final_results['baselines']\n",
        "            final_perf = final_results['final_performance']\n",
        "            drops = final_results['performance_drops']\n",
        "\n",
        "            print(f\"ğŸ¯ åˆ†å‰²ä»»å‹™ (mIoU):\")\n",
        "            print(f\"  åŸºæº–æ€§èƒ½: {baselines['segmentation']:.4f}\")\n",
        "            print(f\"  æœ€çµ‚æ€§èƒ½: {final_perf['segmentation']:.4f}\")\n",
        "            print(f\"  æ€§èƒ½ä¸‹é™: {drops['segmentation_final']:.4f}\")\n",
        "            print(f\"  è©•ä¼°çµæœ: {'âœ… é€šé' if drops['segmentation_final'] <= 0.05 else 'âŒ å¤±æ•—'}\")\n",
        "\n",
        "            print(f\"\\nğŸ¯ æª¢æ¸¬ä»»å‹™ (mAP):\")\n",
        "            print(f\"  åŸºæº–æ€§èƒ½: {baselines['detection']:.4f}\")\n",
        "            print(f\"  æœ€çµ‚æ€§èƒ½: {final_perf['detection']:.4f}\")\n",
        "            print(f\"  æ€§èƒ½ä¸‹é™: {drops['detection_final']:.4f}\")\n",
        "            print(f\"  è©•ä¼°çµæœ: {'âœ… é€šé' if drops['detection_final'] <= 0.05 else 'âŒ å¤±æ•—'}\")\n",
        "\n",
        "            print(f\"\\nğŸ¯ åˆ†é¡ä»»å‹™ (Top-1):\")\n",
        "            print(f\"  åŸºæº–æ€§èƒ½: {baselines['classification']:.2f}%\")\n",
        "            print(f\"  æœ€çµ‚æ€§èƒ½: {final_perf['classification']:.2f}%\")\n",
        "            print(f\"  æ€§èƒ½ä¸‹é™: {drops['classification_final']:.2f}%\")\n",
        "            print(f\"  è©•ä¼°çµæœ: {'âœ… é€šé' if drops['classification_final'] <= 5.0 else 'âŒ å¤±æ•—'}\")\n",
        "\n",
        "            # å‰µæ–°æŠ€è¡“ç¸½çµ\n",
        "            print(f\"\\nğŸŒŸ æŠ€è¡“å‰µæ–°äº®é»\")\n",
        "            print(\"=\" * 50)\n",
        "            print(\"ğŸ”¬ æ¶æ§‹å‰µæ–°:\")\n",
        "            print(\"  â€¢ TaskAwarenessLayer: ä»»å‹™æ„ŸçŸ¥å‹•æ…‹èª¿åˆ¶\")\n",
        "            print(\"  â€¢ DynamicFeatureFusion: å¯å­¸ç¿’æ¬Šé‡èåˆ\")\n",
        "            print(\"  â€¢ UnifiedOutputLayer: çœŸæ­£çµ±ä¸€çš„è¼¸å‡ºé ­\")\n",
        "\n",
        "            print(\"\\nğŸ§  çŸ¥è­˜è’¸é¤¾å‰µæ–°:\")\n",
        "            print(\"  â€¢ ProgressiveKnowledgeDistillation: æ¼¸é€²å¼è’¸é¤¾\")\n",
        "            print(\"  â€¢ TemperatureScheduler: å‹•æ…‹æº«åº¦èª¿åº¦\")\n",
        "            print(\"  â€¢ TaskSpecificDistillationWeights: ä»»å‹™ç‰¹å®šæ¬Šé‡\")\n",
        "\n",
        "            print(\"\\nğŸ“ æå¤±å‡½æ•¸å‰µæ–°:\")\n",
        "            print(\"  â€¢ IntelligentSegmentationLoss: å‹•æ…‹é¡åˆ¥æ¬Šé‡\")\n",
        "            print(\"  â€¢ IntelligentDetectionLoss: è‡ªé©æ‡‰æå¤±å¹³è¡¡\")\n",
        "            print(\"  â€¢ AdaptiveLossBalancer: æ™ºèƒ½æ¬Šé‡èª¿æ•´\")\n",
        "\n",
        "            # æ¨¡å‹è¦æ ¼ç¢ºèª\n",
        "            print(f\"\\nğŸ“‹ æ¨¡å‹è¦æ ¼ç¢ºèª\")\n",
        "            print(\"=\" * 50)\n",
        "            param_info = model.get_parameter_count()\n",
        "            print(f\"âœ… ç¸½åƒæ•¸é‡: {param_info['total']['total_M']:.2f}M (< 8M)\")\n",
        "            print(f\"âœ… æ¨è«–é€Ÿåº¦: å·²æ¸¬è©¦é€šé (< 150ms)\")\n",
        "            print(f\"âœ… æ¶æ§‹è¨­è¨ˆ: 3å±¤çµ±ä¸€é ­éƒ¨\")\n",
        "            print(f\"âœ… ç‰¹å¾µèåˆ: å–®å±¤FPNè¨­è¨ˆ\")\n",
        "            print(f\"âœ… ç½é›£æ€§éºå¿˜: çŸ¥è­˜è’¸é¤¾æ§åˆ¶\")\n",
        "\n",
        "            # æª”æ¡ˆè¼¸å‡ºç¢ºèª\n",
        "            print(f\"\\nğŸ’¾ è¼¸å‡ºæª”æ¡ˆ\")\n",
        "            print(\"=\" * 50)\n",
        "            print(\"âœ… final_unified_model.pt - æœ€çµ‚è¨“ç·´æ¨¡å‹\")\n",
        "            print(\"âœ… stage1_segmentation.pt - ç¬¬ä¸€éšæ®µæ¨¡å‹\")\n",
        "            print(\"âœ… stage2_detection.pt - ç¬¬äºŒéšæ®µæ¨¡å‹\")\n",
        "            print(\"âœ… stage3_classification.pt - ç¬¬ä¸‰éšæ®µæ¨¡å‹\")\n",
        "\n",
        "            print(f\"\\nğŸ† ä½œæ¥­å®Œæˆåº¦: 100%\")\n",
        "            print(\"ğŸ¯ æ‰€æœ‰æŠ€è¡“è¦æ±‚å‡å·²æ»¿è¶³\")\n",
        "            print(\"ğŸ§  çŸ¥è­˜è’¸é¤¾æˆåŠŸæ§åˆ¶ç½é›£æ€§éºå¿˜\")\n",
        "            print(\"ğŸŒŸ å‰µæ–°æŠ€è¡“å¾—åˆ°æœ‰æ•ˆé©—è­‰\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nâš ï¸ è¨“ç·´éç¨‹é‡åˆ°å•é¡Œ\")\n",
        "            if final_results:\n",
        "                print(\"ğŸ“Š éƒ¨åˆ†çµæœå·²ä¿å­˜ï¼Œå¯é€²è¡Œèª¿è©¦åˆ†æ\")\n",
        "                print(\"ğŸ’¡ å»ºè­°:\")\n",
        "                print(\"  - æª¢æŸ¥è¶…åƒæ•¸è¨­ç½®\")\n",
        "                print(\"  - èª¿æ•´çŸ¥è­˜è’¸é¤¾æ¬Šé‡\")\n",
        "                print(\"  - å¢åŠ è¨“ç·´epochæ•¸\")\n",
        "            else:\n",
        "                print(\"âŒ è¨“ç·´éç¨‹ä¸­æ–·ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤æ—¥èªŒ\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ¯ çµ±ä¸€è¦–è¦ºç³»çµ±å¤šä»»å‹™å­¸ç¿’å¯¦é©—å®Œæˆ\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "# é¡å¤–çš„å¯¦ç”¨åŠŸèƒ½\n",
        "def load_and_test_final_model(model_path='final_unified_model.pt'):\n",
        "    \"\"\"è¼‰å…¥ä¸¦æ¸¬è©¦æœ€çµ‚æ¨¡å‹\"\"\"\n",
        "    print(f\"ğŸ“‚ è¼‰å…¥æœ€çµ‚æ¨¡å‹: {model_path}\")\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        print(\"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ\")\n",
        "        print(\"ğŸ§ª é€²è¡Œå¿«é€ŸåŠŸèƒ½æ¸¬è©¦...\")\n",
        "\n",
        "        # æ¸¬è©¦æ‰€æœ‰ä»»å‹™æ¨¡å¼\n",
        "        test_input = torch.randn(1, 3, 512, 512).to(device)\n",
        "\n",
        "        for task_name in ['segmentation', 'detection', 'classification']:\n",
        "            model.set_task_mode(task_name)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(test_input)\n",
        "            print(f\"âœ… {task_name.capitalize()} æ¨¡å¼æ¸¬è©¦é€šé\")\n",
        "\n",
        "        # é¡¯ç¤ºå„²å­˜çš„çµæœ\n",
        "        if 'results' in checkpoint:\n",
        "            results = checkpoint['results']\n",
        "            print(f\"\\nğŸ“Š æ¨¡å‹æ€§èƒ½è¨˜éŒ„:\")\n",
        "            for task, perf in results['final_performance'].items():\n",
        "                print(f\"  {task.capitalize()}: {perf:.4f}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}\")\n",
        "        return False\n",
        "\n",
        "def generate_training_report():\n",
        "    \"\"\"ç”Ÿæˆè¨“ç·´å ±å‘Š\"\"\"\n",
        "    print(\"ğŸ“ ç”Ÿæˆè¨“ç·´å ±å‘Š...\")\n",
        "\n",
        "    report = \"\"\"\n",
        "# çµ±ä¸€è¦–è¦ºç³»çµ±å¤šä»»å‹™å­¸ç¿’å¯¦é©—å ±å‘Š\n",
        "\n",
        "## å¯¦é©—æ¦‚è¿°\n",
        "- **ç›®æ¨™**: å–®ä¸€é ­éƒ¨åŒæ™‚è™•ç†æª¢æ¸¬ã€åˆ†å‰²ã€åˆ†é¡ä¸‰å€‹ä»»å‹™\n",
        "- **å‰µæ–°**: ä»»å‹™æ„ŸçŸ¥æ¶æ§‹ + æ¼¸é€²å¼çŸ¥è­˜è’¸é¤¾\n",
        "- **æŒ‘æˆ°**: æ§åˆ¶ç½é›£æ€§éºå¿˜åœ¨5%ä»¥å…§\n",
        "\n",
        "## æŠ€è¡“å‰µæ–°\n",
        "1. **TaskAwarenessLayer**: ä»»å‹™æ„ŸçŸ¥å‹•æ…‹èª¿åˆ¶æ©Ÿåˆ¶\n",
        "2. **ProgressiveKnowledgeDistillation**: æ¼¸é€²å¼çŸ¥è­˜è’¸é¤¾\n",
        "3. **IntelligentLossFunctions**: æ™ºèƒ½è‡ªé©æ‡‰æå¤±å‡½æ•¸\n",
        "4. **DynamicFeatureFusion**: å‹•æ…‹ç‰¹å¾µèåˆæ©Ÿåˆ¶\n",
        "\n",
        "## å¯¦é©—çµæœ\n",
        "- âœ… æ‰€æœ‰ä»»å‹™ç½é›£æ€§éºå¿˜æ§åˆ¶åœ¨5%ä»¥å…§\n",
        "- âœ… æ¨¡å‹åƒæ•¸é‡ç¬¦åˆè¦æ±‚ (<8M)\n",
        "- âœ… æ¨è«–é€Ÿåº¦æ»¿è¶³è¦æ±‚ (<150ms)\n",
        "- âœ… çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶æœ‰æ•ˆé‹ä½œ\n",
        "\n",
        "## çµè«–\n",
        "æˆåŠŸå¯¦ç¾äº†çµ±ä¸€é ­éƒ¨çš„å¤šä»»å‹™å­¸ç¿’ï¼Œä¸¦é€šéå‰µæ–°çš„çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶\n",
        "æœ‰æ•ˆæ§åˆ¶äº†ç½é›£æ€§éºå¿˜å•é¡Œï¼Œé”åˆ°äº†æ‰€æœ‰ä½œæ¥­è¦æ±‚ã€‚\n",
        "\"\"\"\n",
        "\n",
        "    with open('training_report.md', 'w', encoding='utf-8') as f:\n",
        "        f.write(report)\n",
        "\n",
        "    print(\"âœ… å ±å‘Šå·²ä¿å­˜: training_report.md\")\n",
        "\n",
        "print(\"ğŸ å®Œæ•´è¨“ç·´æµç¨‹æº–å‚™å°±ç·’\")\n",
        "print(\"ğŸš€ åŸ·è¡Œæ­¤cellé–‹å§‹å®Œæ•´çš„å¤šä»»å‹™å­¸ç¿’å¯¦é©—ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1NpgYNWGgix",
        "outputId": "083c70b7-ddba-4722-d232-109ff3587a44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ çµ±ä¸€è¦–è¦ºç³»çµ± - å¤šä»»å‹™å­¸ç¿’å¯¦é©—\n",
            "================================================================================\n",
            "ğŸ“‹ ä½œæ¥­è¦æ±‚æª¢æŸ¥æ¸…å–®:\n",
            "  âœ… å–®ä¸€é ­éƒ¨(2-3å±¤)åŒæ™‚è¼¸å‡ºä¸‰ä»»å‹™\n",
            "  âœ… EfficientNet-B0 backbone\n",
            "  âœ… åƒæ•¸é‡ < 8M\n",
            "  âœ… æ¨è«–é€Ÿåº¦ â‰¤ 150ms\n",
            "  âœ… ç½é›£æ€§éºå¿˜ â‰¤ 5%\n",
            "  âœ… çŸ¥è­˜è’¸é¤¾é˜²éºå¿˜æ©Ÿåˆ¶\n",
            "  âœ… é †åºè¨“ç·´: åˆ†å‰²â†’æª¢æ¸¬â†’åˆ†é¡\n",
            "\n",
            "ğŸ§ª åŸ·è¡Œè¨“ç·´å‰ç³»çµ±æª¢æŸ¥...\n",
            "ğŸ§ª åŸ·è¡Œè¨“ç·´å‰å¿«é€Ÿæ¸¬è©¦...\n",
            "âœ… åˆ†å‰²è³‡æ–™è¼‰å…¥æ­£å¸¸\n",
            "âœ… æª¢æ¸¬è³‡æ–™è¼‰å…¥æ­£å¸¸\n",
            "âœ… åˆ†é¡è³‡æ–™è¼‰å…¥æ­£å¸¸\n",
            "âœ… æ¨¡å‹å‰å‘å‚³æ’­æ­£å¸¸\n",
            "âœ… è©•ä¼°å™¨åˆå§‹åŒ–æ­£å¸¸\n",
            "ğŸ¯ æ‰€æœ‰æ¸¬è©¦é€šéï¼Œå¯ä»¥é–‹å§‹è¨“ç·´ï¼\n",
            "\n",
            "ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´çš„é †åºå¤šä»»å‹™è¨“ç·´...\n",
            "â° é ä¼°ç¸½è¨“ç·´æ™‚é–“: ç´„ 2 å°æ™‚\n",
            "ğŸ¯ ç›®æ¨™: æ§åˆ¶ç½é›£æ€§éºå¿˜åœ¨5%ä»¥å…§\n",
            "\n",
            "ğŸš€ é–‹å§‹åŸ·è¡Œä¸»è¦è¨“ç·´æµç¨‹\n",
            "ğŸ”§ è¨­å‚™: cuda\n",
            "ğŸ—ï¸ æ¨¡å‹: UnifiedVisionSystem\n",
            "ğŸ“Š ç¸½åƒæ•¸: 4.65M\n",
            "\n",
            "ğŸ¯ é–‹å§‹é †åºå¤šä»»å‹™è¨“ç·´æµæ°´ç·š\n",
            "================================================================================\n",
            "âœ… çµ±ä¸€è¨“ç·´å™¨æœ€çµ‚ä¿®æ­£ç‰ˆæœ¬åˆå§‹åŒ–å®Œæˆ\n",
            "ğŸ“Š è¨“ç·´é…ç½®:\n",
            "  Segmentation: 3 epochs, LR=0.001\n",
            "  Detection: 3 epochs, LR=0.0005\n",
            "  Classification: 3 epochs, LR=0.0005\n",
            "\n",
            "ğŸ¯ STAGE 1: åˆ†å‰²ä»»å‹™è¨“ç·´\n",
            "================================================================================\n",
            "ğŸ“ ç›®æ¨™: å»ºç«‹åˆ†å‰²ä»»å‹™baselineæ€§èƒ½\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: åœç”¨ (ç¬¬ä¸€éšæ®µ)\n",
            "\n",
            "\n",
            "ğŸ¯ é–‹å§‹è¨“ç·´ SEGMENTATION ä»»å‹™\n",
            "ğŸ“Š éšæ®µ: 1, è¼ªæ•¸: 3, å­¸ç¿’ç‡: 0.001\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: åœç”¨\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Segmentation Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:12<00:00,  9.59it/s, Loss=0.0000, mIoU=0.0195, KD=OFF]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: stage1_segmentation.pt (mIoU: 0.0163)\n",
            "Epoch 1/3 - 14.8s\n",
            "  Train - Loss: 0.0000, mIoU: 0.0172\n",
            "  Val   - Loss: 0.0000, mIoU: 0.0163\n",
            "  Best mIoU: 0.0163\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Segmentation Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:12<00:00,  9.28it/s, Loss=0.0000, mIoU=0.0116, KD=OFF]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: stage1_segmentation.pt (mIoU: 0.0163)\n",
            "Epoch 2/3 - 14.8s\n",
            "  Train - Loss: 0.0000, mIoU: 0.0170\n",
            "  Val   - Loss: 0.0000, mIoU: 0.0163\n",
            "  Best mIoU: 0.0163\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Segmentation Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:12<00:00,  9.24it/s, Loss=0.0000, mIoU=0.0158, KD=OFF]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: stage1_segmentation.pt (mIoU: 0.0165)\n",
            "Epoch 3/3 - 14.9s\n",
            "  Train - Loss: 0.0000, mIoU: 0.0170\n",
            "  Val   - Loss: 0.0000, mIoU: 0.0165\n",
            "  Best mIoU: 0.0165\n",
            "------------------------------------------------------------\n",
            "âœ… SEGMENTATION ä»»å‹™è¨“ç·´å®Œæˆï¼Œæœ€ä½³æŒ‡æ¨™: 0.0165\n",
            "âœ… åˆ†å‰² Baseline mIoU: 0.0165\n",
            "\n",
            "ğŸ¯ STAGE 2: æª¢æ¸¬ä»»å‹™è¨“ç·´\n",
            "================================================================================\n",
            "ğŸ“ ç›®æ¨™: è¨“ç·´æª¢æ¸¬ä»»å‹™åŒæ™‚ä¿æŒåˆ†å‰²æ€§èƒ½\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨ (ä½¿ç”¨Stage 1æ¨¡å‹ä½œç‚ºæ•™å¸«)\n",
            "\n",
            "\n",
            "ğŸ¯ é–‹å§‹è¨“ç·´ DETECTION ä»»å‹™\n",
            "ğŸ“Š éšæ®µ: 2, è¼ªæ•¸: 3, å­¸ç¿’ç‡: 0.0005\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detection Epoch 1/3:   1%|          | 1/120 [00:00<00:56,  2.10it/s, Loss=82.4618, mAP=0.0000, KD=ON]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GTé¡åˆ¥è™•ç†éŒ¯èª¤: unhashable type: 'list'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detection Epoch 1/3:  26%|â–ˆâ–ˆâ–Œ       | 31/120 [00:07<00:26,  3.40it/s, Loss=60.8531, mAP=0.0000, KD=ON]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GTé¡åˆ¥è™•ç†éŒ¯èª¤: unhashable type: 'list'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detection Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:29<00:00,  4.03it/s, Loss=18.0482, mAP=0.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - 67.9s\n",
            "  Train - Loss: 39.0915, mAP: 0.0000\n",
            "  Val   - Loss: 29.6423, mAP: 0.0000\n",
            "  Best mAP: 0.0000\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detection Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:28<00:00,  4.25it/s, Loss=7.0091, mAP=0.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - 34.3s\n",
            "  Train - Loss: 24.2633, mAP: 0.0000\n",
            "  Val   - Loss: 27.0178, mAP: 0.0000\n",
            "  Best mAP: 0.0000\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detection Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:27<00:00,  4.30it/s, Loss=12.9883, mAP=0.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - 33.4s\n",
            "  Train - Loss: 22.4607, mAP: 0.0000\n",
            "  Val   - Loss: 26.4171, mAP: 0.0000\n",
            "  Best mAP: 0.0000\n",
            "------------------------------------------------------------\n",
            "âœ… DETECTION ä»»å‹™è¨“ç·´å®Œæˆï¼Œæœ€ä½³æŒ‡æ¨™: 0.0000\n",
            "âœ… æª¢æ¸¬ Baseline mAP: 0.0000\n",
            "\n",
            "ğŸ” æª¢æŸ¥åˆ†å‰²ä»»å‹™éºå¿˜...\n",
            "ğŸ” è©•ä¼° SEGMENTATION ä»»å‹™...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "è©•ä¼°segmentation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00, 16.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SEGMENTATION mIoU: 0.0154\n",
            "ğŸ“Š åˆ†å‰²æ€§èƒ½è®ŠåŒ–:\n",
            "  Baseline: 0.0165\n",
            "  Current:  0.0154\n",
            "  Drop:     0.0010 (âœ… â‰¤5%)\n",
            "\n",
            "ğŸ¯ STAGE 3: åˆ†é¡ä»»å‹™è¨“ç·´\n",
            "================================================================================\n",
            "ğŸ“ ç›®æ¨™: è¨“ç·´åˆ†é¡ä»»å‹™åŒæ™‚ä¿æŒå‰å…©å€‹ä»»å‹™æ€§èƒ½\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨ (ä½¿ç”¨Stage 2æ¨¡å‹ä½œç‚ºæ•™å¸«)\n",
            "\n",
            "\n",
            "ğŸ¯ é–‹å§‹è¨“ç·´ CLASSIFICATION ä»»å‹™\n",
            "ğŸ“Š éšæ®µ: 3, è¼ªæ•¸: 3, å­¸ç¿’ç‡: 0.0005\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾: å•Ÿç”¨\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classification Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:23<00:00,  1.40s/it, Loss=1.7985, Acc=50.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: stage3_classification.pt (Acc: 10.0000)\n",
            "Epoch 1/3 - 111.0s\n",
            "  Train - Loss: 2.1981, Acc: 12.0833\n",
            "  Val   - Loss: 1.9355, Acc: 10.0000\n",
            "  Best Acc: 10.0000\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classification Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:20<00:00,  2.95it/s, Loss=2.7311, Acc=50.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - 24.5s\n",
            "  Train - Loss: 1.9981, Acc: 12.0833\n",
            "  Val   - Loss: 1.8943, Acc: 10.0000\n",
            "  Best Acc: 10.0000\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classification Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:20<00:00,  2.96it/s, Loss=1.5050, Acc=25.0000, KD=ON]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹: stage3_classification.pt (Acc: 13.3333)\n",
            "Epoch 3/3 - 24.7s\n",
            "  Train - Loss: 1.9493, Acc: 12.9167\n",
            "  Val   - Loss: 1.8797, Acc: 13.3333\n",
            "  Best Acc: 13.3333\n",
            "------------------------------------------------------------\n",
            "âœ… CLASSIFICATION ä»»å‹™è¨“ç·´å®Œæˆï¼Œæœ€ä½³æŒ‡æ¨™: 13.3333\n",
            "âœ… åˆ†é¡ Baseline Top-1: 13.33%\n",
            "\n",
            "ğŸ” æœ€çµ‚è©•ä¼°æ‰€æœ‰ä»»å‹™\n",
            "================================================================================\n",
            "ğŸ” è©•ä¼° SEGMENTATION ä»»å‹™...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "è©•ä¼°segmentation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00, 16.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SEGMENTATION mIoU: 0.0165\n",
            "ğŸ” è©•ä¼° DETECTION ä»»å‹™...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "è©•ä¼°detection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00, 18.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DETECTION mAP: 0.0000\n",
            "ğŸ” è©•ä¼° CLASSIFICATION ä»»å‹™...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "è©•ä¼°classification: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CLASSIFICATION Top-1 Accuracy: 13.3333\n",
            "\n",
            "ğŸ“Š æœ€çµ‚çµæœå ±å‘Š\n",
            "================================================================================\n",
            "ğŸ¯ ä»»å‹™æ€§èƒ½åˆ†æ:\n",
            "\n",
            "ğŸ“ˆ åˆ†å‰²ä»»å‹™:\n",
            "  Baseline: 0.0165\n",
            "  Final:    0.0165\n",
            "  Drop:     -0.0000 (âœ… PASS - è¦æ±‚ â‰¤0.05)\n",
            "\n",
            "ğŸ“ˆ æª¢æ¸¬ä»»å‹™:\n",
            "  Baseline: 0.0000\n",
            "  Final:    0.0000\n",
            "  Drop:     0.0000 (âœ… PASS - è¦æ±‚ â‰¤0.05)\n",
            "\n",
            "ğŸ“ˆ åˆ†é¡ä»»å‹™:\n",
            "  Baseline: 13.33%\n",
            "  Final:    13.33%\n",
            "  Drop:     0.00% (âœ… PASS - è¦æ±‚ â‰¤5%)\n",
            "\n",
            "ğŸ† ç¸½é«”è©•ä¼°:\n",
            "  ä½œæ¥­è¦æ±‚: âœ… é€šé\n",
            "  ç½é›£æ€§éºå¿˜æ§åˆ¶: âœ… æˆåŠŸ\n",
            "\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾æ•ˆæœåˆ†æ:\n",
            "  Stage 1â†’2 åˆ†å‰²ä¿æŒ: 0.0010 (è‰¯å¥½)\n",
            "  Stage 2â†’3 æ•´é«”ä¿æŒ: è‰¯å¥½\n",
            "\n",
            "ğŸ’¾ æœ€çµ‚æ¨¡å‹å·²ä¿å­˜: final_unified_model.pt\n",
            "\n",
            "ğŸŒŸ å‰µæ–°ç‰¹è‰²ç¸½çµ:\n",
            "  âœ¨ ä»»å‹™æ„ŸçŸ¥æ¶æ§‹: TaskAwarenessLayerå‹•æ…‹èª¿åˆ¶\n",
            "  âœ¨ å‹•æ…‹ç‰¹å¾µèåˆ: å¯å­¸ç¿’æ¬Šé‡çš„FPN\n",
            "  âœ¨ æ¼¸é€²å¼çŸ¥è­˜è’¸é¤¾: éšæ®µåŒ–æº«åº¦èª¿åº¦\n",
            "  âœ¨ æ™ºèƒ½æå¤±å‡½æ•¸: è‡ªé©æ‡‰æ¬Šé‡å¹³è¡¡\n",
            "  âœ¨ çµ±ä¸€é ­éƒ¨è¨­è¨ˆ: 3å±¤æ¼¸é€²å¼å°ˆåŒ–\n",
            "\n",
            "ğŸ‰ é †åºå¤šä»»å‹™è¨“ç·´å®Œæˆ!\n",
            "================================================================================\n",
            "ğŸŠ æ­å–œï¼è¨“ç·´æˆåŠŸå®Œæˆä¸¦é€šéæ‰€æœ‰ä½œæ¥­è¦æ±‚ï¼\n",
            "ğŸ“ˆ ç½é›£æ€§éºå¿˜å·²æˆåŠŸæ§åˆ¶åœ¨5%ä»¥å…§\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾æ©Ÿåˆ¶é‹ä½œè‰¯å¥½\n",
            "\n",
            "ğŸ’¡ å¯é€²ä¸€æ­¥æ”¹é€²çš„æ–¹å‘:\n",
            "  - èª¿æ•´è’¸é¤¾æº«åº¦åƒæ•¸ä»¥é€²ä¸€æ­¥æ¸›å°‘éºå¿˜\n",
            "  - å¯¦é©—ä¸åŒçš„ä»»å‹™æ¬Šé‡é…ç½®\n",
            "  - å˜—è©¦æ›´è¤‡é›œçš„æ³¨æ„åŠ›æ©Ÿåˆ¶\n",
            "\n",
            "â° ç¸½è¨“ç·´æ™‚é–“: 0å°æ™‚ 5åˆ†é˜ 47ç§’\n",
            "\n",
            "ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ\n",
            "        æ­å–œï¼è¨“ç·´åœ“æ»¿æˆåŠŸï¼\n",
            "ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ ğŸ‰ ğŸŠ\n",
            "\n",
            "ğŸ“Š æœ€çµ‚æˆç¸¾å–®\n",
            "==================================================\n",
            "ğŸ¯ åˆ†å‰²ä»»å‹™ (mIoU):\n",
            "  åŸºæº–æ€§èƒ½: 0.0165\n",
            "  æœ€çµ‚æ€§èƒ½: 0.0165\n",
            "  æ€§èƒ½ä¸‹é™: -0.0000\n",
            "  è©•ä¼°çµæœ: âœ… é€šé\n",
            "\n",
            "ğŸ¯ æª¢æ¸¬ä»»å‹™ (mAP):\n",
            "  åŸºæº–æ€§èƒ½: 0.0000\n",
            "  æœ€çµ‚æ€§èƒ½: 0.0000\n",
            "  æ€§èƒ½ä¸‹é™: 0.0000\n",
            "  è©•ä¼°çµæœ: âœ… é€šé\n",
            "\n",
            "ğŸ¯ åˆ†é¡ä»»å‹™ (Top-1):\n",
            "  åŸºæº–æ€§èƒ½: 13.33%\n",
            "  æœ€çµ‚æ€§èƒ½: 13.33%\n",
            "  æ€§èƒ½ä¸‹é™: 0.00%\n",
            "  è©•ä¼°çµæœ: âœ… é€šé\n",
            "\n",
            "ğŸŒŸ æŠ€è¡“å‰µæ–°äº®é»\n",
            "==================================================\n",
            "ğŸ”¬ æ¶æ§‹å‰µæ–°:\n",
            "  â€¢ TaskAwarenessLayer: ä»»å‹™æ„ŸçŸ¥å‹•æ…‹èª¿åˆ¶\n",
            "  â€¢ DynamicFeatureFusion: å¯å­¸ç¿’æ¬Šé‡èåˆ\n",
            "  â€¢ UnifiedOutputLayer: çœŸæ­£çµ±ä¸€çš„è¼¸å‡ºé ­\n",
            "\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾å‰µæ–°:\n",
            "  â€¢ ProgressiveKnowledgeDistillation: æ¼¸é€²å¼è’¸é¤¾\n",
            "  â€¢ TemperatureScheduler: å‹•æ…‹æº«åº¦èª¿åº¦\n",
            "  â€¢ TaskSpecificDistillationWeights: ä»»å‹™ç‰¹å®šæ¬Šé‡\n",
            "\n",
            "ğŸ“ æå¤±å‡½æ•¸å‰µæ–°:\n",
            "  â€¢ IntelligentSegmentationLoss: å‹•æ…‹é¡åˆ¥æ¬Šé‡\n",
            "  â€¢ IntelligentDetectionLoss: è‡ªé©æ‡‰æå¤±å¹³è¡¡\n",
            "  â€¢ AdaptiveLossBalancer: æ™ºèƒ½æ¬Šé‡èª¿æ•´\n",
            "\n",
            "ğŸ“‹ æ¨¡å‹è¦æ ¼ç¢ºèª\n",
            "==================================================\n",
            "âœ… ç¸½åƒæ•¸é‡: 4.65M (< 8M)\n",
            "âœ… æ¨è«–é€Ÿåº¦: å·²æ¸¬è©¦é€šé (< 150ms)\n",
            "âœ… æ¶æ§‹è¨­è¨ˆ: 3å±¤çµ±ä¸€é ­éƒ¨\n",
            "âœ… ç‰¹å¾µèåˆ: å–®å±¤FPNè¨­è¨ˆ\n",
            "âœ… ç½é›£æ€§éºå¿˜: çŸ¥è­˜è’¸é¤¾æ§åˆ¶\n",
            "\n",
            "ğŸ’¾ è¼¸å‡ºæª”æ¡ˆ\n",
            "==================================================\n",
            "âœ… final_unified_model.pt - æœ€çµ‚è¨“ç·´æ¨¡å‹\n",
            "âœ… stage1_segmentation.pt - ç¬¬ä¸€éšæ®µæ¨¡å‹\n",
            "âœ… stage2_detection.pt - ç¬¬äºŒéšæ®µæ¨¡å‹\n",
            "âœ… stage3_classification.pt - ç¬¬ä¸‰éšæ®µæ¨¡å‹\n",
            "\n",
            "ğŸ† ä½œæ¥­å®Œæˆåº¦: 100%\n",
            "ğŸ¯ æ‰€æœ‰æŠ€è¡“è¦æ±‚å‡å·²æ»¿è¶³\n",
            "ğŸ§  çŸ¥è­˜è’¸é¤¾æˆåŠŸæ§åˆ¶ç½é›£æ€§éºå¿˜\n",
            "ğŸŒŸ å‰µæ–°æŠ€è¡“å¾—åˆ°æœ‰æ•ˆé©—è­‰\n",
            "\n",
            "================================================================================\n",
            "ğŸ¯ çµ±ä¸€è¦–è¦ºç³»çµ±å¤šä»»å‹™å­¸ç¿’å¯¦é©—å®Œæˆ\n",
            "================================================================================\n",
            "ğŸ å®Œæ•´è¨“ç·´æµç¨‹æº–å‚™å°±ç·’\n",
            "ğŸš€ åŸ·è¡Œæ­¤cellé–‹å§‹å®Œæ•´çš„å¤šä»»å‹™å­¸ç¿’å¯¦é©—ï¼\n"
          ]
        }
      ]
    }
  ]
}