# Unified-OneHead Multi-Task Learning

一個統一頭部的多任務學習系統實現，同時處理物件檢測、語義分割和圖像分類三個視覺任務。

## 🎯 專案概述

本專案實現了符合作業要求的統一視覺系統，核心特色包括：

- **單一頭部架構**: 2-3層統一頭部同時輸出三個任務結果
- **知識蒸餾機制**: 實現漸進式知識蒸餾以防止災難性遺忘
- **資源效率**: 4.65M參數，推論速度16.99ms
- **完整實現**: 滿足所有作業的技術要求

**注意**: 雖然系統架構完整且能正常運行，但訓練效果不佳，模型性能接近隨機水準。

## 📋 作業要求達成

- ✅ 單一頭部(2-3層)同時輸出三任務
- ✅ EfficientNet-B0 backbone
- ✅ 參數量 < 8M (實際: 4.65M)
- ✅ 推論速度 ≤ 150ms (實際: 16.99ms)
- ✅ 災難性遺忘 ≤ 5% (技術上滿足，但因基準性能極低)
- ✅ 知識蒸餾防遺忘機制
- ✅ 順序訓練: 分割→檢測→分類

## ⚠️ 性能說明

本實現在架構和技術要求上完全符合作業規範，但存在以下問題：
- **訓練效果不佳**: 各任務性能接近隨機水準
- **分割 mIoU**: 0.0165 (極低)
- **檢測 mAP**: 0.0000 (無效)
- **分類準確率**: 13.33% (略高於隨機的10%)

推測問題可能出現在損失函數設計或訓練策略上，但架構本身能正常運行。

## 📁 專案結構

```
unified-multitask-learning/
├── colab.ipynb                 # 主要訓練notebook
├── report.md                   # 實驗報告
├── README.md                   # 專案說明文件
└── llm_dialogs.zip            # LLM對話記錄
```

## 🚀 使用方法

### 1. 環境準備

在Google Colab中運行：
```python
# 所有必要的套件安裝都在notebook中完成
# 包括: torch, torchvision, efficientnet-pytorch, timm 等
```

### 2. 資料準備

```python
# 資料會自動下載到Google Drive
data_root = "/content/drive/MyDrive/data"
# 包含三個子資料集:
# - mini_coco_det/     (物件檢測)
# - mini_voc_seg/      (語義分割) 
# - imagenette_160/    (圖像分類)
```

### 3. 訓練模型

直接執行 `colab.ipynb` 中的所有cell，完整訓練約需5-10分鐘。

## 🏗️ 架構設計

### 核心架構
```
Input (3×512×512)
    ↓
EfficientNet-B0 Backbone (凍結前8層)
    ↓
DynamicFeatureFusion Neck (單層FPN)
    ↓
TaskAdaptiveProcessor Head (3層統一頭部)
    ↓
三任務同時輸出
```

### 主要組件

1. **TaskAwarenessLayer**: 任務感知動態調制
2. **DynamicFeatureFusion**: 可學習權重融合
3. **UnifiedOutputLayer**: 統一多任務輸出頭部
4. **ProgressiveKnowledgeDistillation**: 漸進式知識蒸餾

## 📊 實驗結果

### 資源效率

- **參數量**: 4.65M / 8M (58.1%)
- **訓練時間**: 5分47秒 / 2小時 (4.8%)
- **推論速度**: 16.99ms / 150ms (11.3%)

### 性能結果

| 任務 | 基準性能 | 最終性能 | 狀態 |
|------|----------|----------|------|
| 分割 (mIoU) | 0.0165 | 0.0165 | ❌ 極低 |
| 檢測 (mAP) | 0.0000 | 0.0000 | ❌ 無效 |
| 分類 (Top-1) | 13.33% | 13.33% | ❌ 接近隨機 |

## 🔧 已知問題

1. **訓練效果不佳**: 所有任務性能都極低
2. **可能原因**: 
   - 損失函數設計問題
   - 梯度消失或爆炸
   - 多任務權重平衡問題
   - 知識蒸餾干擾正常學習

3. **未解決問題**:
   - 模型收斂困難
   - 損失函數調試需要
   - 超參數優化

## 💡 改進方向

1. **損失函數重新設計**: 簡化多任務損失組合
2. **訓練策略調整**: 降低知識蒸餾權重或分階段引入
3. **學習率調優**: 針對不同任務使用不同學習率
4. **架構簡化**: 減少複雜度以便調試

## 📝 結論

本專案在**架構實現**方面完全達到作業要求：
- ✅ 符合所有技術規範
- ✅ 滿足資源限制
- ✅ 實現完整的訓練流程
- ✅ 系統能正常運行

但在**訓練效果**方面存在問題，模型性能接近隨機水準。這表明在滿足架構要求的同時，訓練策略和損失函數設計仍需進一步優化。

---

**注意**: 本專案主要展示架構實現和作業要求的達成，實際應用效果有限。
